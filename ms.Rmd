---
title: 'On investigating heterogeneity in psychological phenomena'
shorttitle: Heterogeneity in psychology
leftheader: Heterogeneity in psychology
author: 
  - name: Matti Vuorre
    affiliation: 1
    corresponding: yes
    address: Tilburg School of Social and Behavioral Sciences, Tilburg University
    email: mjvuorre@uvt.nl
  - name: Matthew Kay
    affiliation: 2
  - name: Niall Bolger
    affiliation: 3
affiliation:
  - id: 1
    institution: Department of Social Psychology, Tilburg School of Social and Behavioral Sciences, Tilburg University
  - id: 2
    institution: Computer Science and Communication Studies, Northwestern University
  - id: 3
    institution: Department of Psychology, Columbia University
abstract: |
  Advances in statistics and data collection methods have brought variability in psychological phenomena to the forefront of theoretical development. Yet, established methods and practices for studying heterogeneity underestimate the true uncertainty in those estimates. In the current work, we aim to deliver methods and guidelines for more rigorous treatments of heterogeneity in psychological phenomena. We provide a walkthrough of methods for i. estimating, ii. summarising, and iii. describing heterogeneity. Although other methods for incorporating estimation uncertainty are available, the methods we propose---involving bayesian hierarchical models---are especially suitable for investigating heterogeneity because they naturally describe uncertainty in all model parameters. We hope that the methods we discuss would help researchers to widen their inferential focus from statistical averages to include statistical heterogeneity in psychological phenomena.
keywords: variation, heterogeneity, hierarchical models, mixed models, methodology
authornote: |
  \noindent \textbf{This working paper is not yet peer reviewed.}
wordcount: 5196
bibliography: references.bib
floatsintext: yes
numbersections: false
linenumbers: no
draft: no
mask: no
figurelist: no
tablelist: no
footnotelist: no
documentclass: apa7
classoption: jou
header-includes:
  - |
    \usepackage{float}
    \setlength{\parskip}{4pt}
output: 
  papaja::apa6_pdf:
    number_sections: true
    keep_tex: false
    highlight: kate
  papaja::apa6_docx: 
    number_sections: true
    keep_tex: false
---

```{r setup, include = FALSE}
# Packages
library(papaja)
library(janitor)
library(scales)
library(ellipse)
library(knitr)
library(readxl)
library(latex2exp)
library(lme4)
library(ggpp)
library(patchwork)
library(latex2exp)
library(ggdist)
library(ggstance)
library(tidybayes)
library(distributional)
library(posterior)
library(parameters)
library(brms)
library(tidyverse)

# Output options
opts_chunk$set(
  eval = TRUE,
  cache = TRUE,
  warning = FALSE,
  error = TRUE,
  message = FALSE
)

# Plotting options
theme_set(
  theme_classic(base_size = 9) +
    theme(
      strip.text = element_text(color = "black", hjust = 0),
      strip.background = element_rect(color = NA, fill = NA),
      strip.text.x = element_text(size = rel(0.9)),
      line = element_line(linewidth = .25),
      plot.tag = element_text(size = rel(1))
    )
)

# Model estimation options
dir.create("models", FALSE)
options(
  mc.cores = 4
)
if (require(cmdstanr)) {
  options(
    brms.backend = "cmdstanr",
    brms.threads = 2
  )
}  
dir.create("data", FALSE)
```

# Introduction

When building and testing theories of psychological phenomena, psychologists have long focused on asking whether an effect exists or not. Yet, establishing that an independent variable affects a dependent variable on average may not be a sufficient description of the phenomenon if the treatment effect is highly variable from one individual to another. The importance of such between-person variation, or *heterogeneity*, for theory development is widely recognized, yet rarely communicated sufficiently in the empirical literature [@bolgerCausalProcessesPsychology2019; @brandCausalEffectHeterogeneity2013]. 

One reason for the scarcity of reporting and interpreting heterogeneity is that psychologists still tend to analyze data with models that obscure the assessment of heterogeneity, such as ANOVA [@bolgerCausalProcessesPsychology2019]. Although more appropriate hierarchical (or multilevel, mixed-effects) models are rapidly becoming more widespread, we believe a second important reason is that researchers do not yet have the conceptual and practical tools required to sufficiently estimate and describe heterogeneity. In the current work, we highlight several practical methods, descriptions, and visualizations that allow researchers to better estimate, interpret, and report heterogeneity in a manner that maximizes empirical results' impact on theory building.

## Current work

Our aim is to outline methods for studying and communicating heterogeneity in a manner that fully takes uncertainty into account. We first introduce an example dataset from social psychology and review established procedures for estimating and communicating the expected heterogeneity in causal effects in the population. We then outline useful summaries of heterogeneity that focus on informative numerical and graphical descriptions, and note how they are limited by established methods' focus on point estimates of model parameters.

We then turn to our proposed method of interrogating and communicating causal effect heterogeneity using probabilistic methods. By estimating probability distributions over model parameters, these bayesian methods are uniquely suitable for examining heterogeneity and researchers' uncertainty about it. Moreover, advances in computational procedures and statistical software make these methods available to researchers with a minimal learning curve beyond established maximum likelihood based methods.

In the following sections, we detail calculations and graphics that make use of bayesian methods in communicating descriptions of heterogeneity such that uncertainty in the model parameters and, subsequently, heterogeneity, is taken into account. We then further extend the practice and consequent benefits of probabilistic inference for causal effect heterogeneity to comparing heterogeneity between populations and across timepoints in further example analyses.

We conclude by discussing additional benefits of probabilistic inference in psychology in general, and for multilevel models specifically. We emphasize that these benefits come with little or no cost to applied practitioners. We also discuss our findings regarding causal effect heterogeneity in light of this new perspective.

# Review of expected heterogeneity in hierarchical models

To begin our exposition, we reproduce the analyses presented in @bolgerCausalProcessesPsychology2019. In their study, which replicated findings first presented in @scholerInflatingDeflatingSelf2014, 62 participants saw twenty positively and twenty negatively valenced words, and judged whether each word was self-descriptive or not. Because most people are typically motivated to view themselves positively, @bolgerCausalProcessesPsychology2019 predicted that response times to positively valenced words would be shorter than to negatively valenced words [@scholerInflatingDeflatingSelf2014]. 

```{r data-bolgeretal, include = FALSE}
# Load, save, & clean example data from Bolger et al. (2019)
path <- "data/bolger-etal.zip"
if (!file.exists(path)) {
  download.file(
    "https://github.com/kzee/heterogeneityproject/archive/refs/heads/master.zip",
    destfile = path
  )
  unzip(path, exdir = str_remove(path, ".zip"), junkpaths = TRUE)
}

# Save variables as numerical & factor
dat <- read_csv("data/bolger-etal/heterogeneity_dataset1_traitvalence.csv") |>
  # Cleaning as in Bolger et al 2019
  filter(
    response.keys == "up",
    scale(rt) < 3,
    !(id %in% c(250, 257, 272))
  ) |>
  # Some more cleaning
  mutate(
    person = factor(id),
    trial,
    valence = factor(
      valenceE,
      levels = c(-0.5, 0.5),
      labels = c("Negative", "Positive")
    ),
    rt = logrt
  ) |>
  select(person, trial, valence, rt) |>
  arrange(person, trial)

contrasts(dat$valence) <- c(-0.5, 0.5)
contrasts(dat$valence)
```

## Model 1

```{r}
#| label: tab-dat1
dat |>
  head() |>
  apa_table(
    span_text_columns = FALSE,
    font_size = "small",
    digits = c(0, 0, 0, 2),
    caption = "First six rows of example dataset 1 (Bolger et al., 2019; Exp 1).",
    note = "rt is log-transformed."
  )
```

In this section, we replicate @bolgerCausalProcessesPsychology2019's analysis, using their openly available data (https://github.com/kzee/heterogeneityproject). We first cleaned the data as in @bolgerCausalProcessesPsychology2019, leaving `r number(nrow(dat), big.mark = ",")` trials from 59 participants that were endorsed as self-relevant. (We present all our code in the online analysis supplement.) We show a sample of these data in Table \@ref(tab:tab-dat1). Then, we estimated the same statistical model with these data (Model 1; equations 1.1-1.3). First, we model the (log) reaction time of subject $j$ on trial $i$ as a random draw from a normal distribution with mean $\eta$ (*eta*, which can differ between trials $i$ and individuals $j$) and standard deviation $\sigma$ (*sigma*):

\begin{equation}
\tag{1.1}
\text{RT}_{ij} \sim \operatorname{Normal}(\eta_{ij}, \sigma^2).
\end{equation}

The lack of subscripts on $\sigma$ indicates that we assume it to be invariant across trials and subjects. (Note that there are better alternatives for modelling reaction times (RT) than modelling the log-transformed RTs as normal, but those are outside the scope of this manuscript.) Then, we specify a model of the mean $\eta_{ij}$ such that the regression coefficients capture our substantive questions: 

\begin{equation}
\tag{1.2}
\eta_{ij} = \beta_0 + \gamma_{0j} + (\beta_1 + \gamma_{1j})\text{V}_{ij}.
\end{equation}

This equation includes two kinds of parameters: $\beta_0$ (*beta*), the intercept, and $\beta_1$, the slope or effect of valence (V), do not have subscripts. That means that they are not further modelled except by way of (optional) prior distributions with fixed hyperparameters. In line with existing conventions in bayesian inference and software, we refer to these as *population level* parameters. From the frequentist perspective, these terms are constants (i.e. do not potentially vary as functions of covariates) and are therefore sometimes "fixed". For all practical purposes, because we do not discuss prior distributions with constant hyperparameters, readers can equate the terms "fixed" and "population level" parameters in the current discussion.

We contrast coded valence such that negative words are coded as -0.5, and positive words as 0.5. This coding results in an intercept that corresponds to the average reaction time across negative and positive words, and a slope coefficient that reflects the difference in log(rt) between negative and positive words. The second set of parameters, $\gamma_{0j}$ (*gamma*) and $\gamma_{1j}$ are person-specific deviations from the average intercept and slope, respectively. That is, $\beta_0 + \gamma_{01}$ is the average reaction time for person $j=1$. The $\gamma$ coefficients have subscripts, which in this context indicates that they are further modelled on covariates---here, index variables for "person" in the data. We refer to these as "group level" parameters, in line with conventions. In the frequentist discourse, these parameters are called "random" parameters [@gelmanDataAnalysisUsing2007]. Again, readers can equate the term "group level" parameters with "random" parameters in the ongoing discussion.

As is standard in multilevel modelling, we model $\gamma_0$ and $\gamma_1$ as multivariate normal distributed:

\begin{equation}
\tag{1.3}
\begin{bmatrix} 
\gamma_{0} \\ \gamma_{1}
\end{bmatrix} \sim 
\operatorname{MVN}(
\begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
\begin{bmatrix} 
\tau_{\gamma_{0}} &\rho_{\gamma_0\gamma_1} \\ 
\rho_{\gamma_0\gamma_1} &\tau_{\gamma_{1}} 
\end{bmatrix}
).
\end{equation}

In these equations, we assume that the subject-specific deviations have means of zero, standard deviations $\tau$ (*tau*), and a correlation $\rho$ (*rho*). Note that the $\gamma$s are zero-centered because the means are added to them in the above linear mixed-effects equation for $\eta_{ij}$. What these equations mean substantively is that the extent to which the effect of valence varies around the average effect ($\beta_1$) is estimated by the standard deviation $\tau_{\gamma_1}$. Moreover, $\rho$ indicates the extent to which individuals' average reaction times correlate with how much their reaction time is affected by valence. 

With data described in Table \@ref(tab:tab-dat1) loaded to R, we can estimate this model using standard maximum likelihood methods as implemented in the R package lme4 [@batesFittingLinearMixedEffects2015; @rcoreteamLanguageEnvironmentStatistical2023].

```{r fit1-lmer}
fit_lmer <- lmer(
  rt ~ 1 + valence + (1 + valence | person),
  data = dat
)
```

```{r}
# Create a table of coefficients
tab_1 <- model_parameters(fit_lmer, effects = "all") |>
  tibble() |>
  select(Parameter, Coefficient, starts_with("CI_"))

# Bootstrap CIs for variance parameters
tab_1[3:6, 3:4] <- confint(
  fit_lmer,
  method = "boot",
  nsim = 100,
  oldNames = FALSE
)[c(1, 3, 2, 4), 1:2]

# Get approx SEs
tab_1 <- tab_1 |> 
  mutate(SE = (CI_high - Coefficient) / 1.96) |> 
  select(1, 2, 5, 3:4)
```

```{r}
#| label: tbl-fit-1
#| cache: false

m1_parnames <- c(
  "$\\beta_0$", "$\\beta_1$",
  "$\\tau_0$", "$\\tau_1$",
  "$\\rho$", "$\\sigma$"
)

tab_1 |>
  mutate(
    mutate(across(where(is.numeric), ~number(.x, .01))),
    CI = str_glue("[{CI_low}, {CI_high}]"),
    Coefficient = ifelse(
      str_starts(Coefficient, "-"), 
      Coefficient, 
      paste0("\\phantom{-}", Coefficient)
    ),
    Parameter = m1_parnames
  ) |> 
  select(
    Parameter, Coefficient, SE, CI
  ) |>
  apa_table(
    span_text_columns = FALSE,
    font_size = "small",
    caption = "Parameter estimates from Model 1.",
    escape = FALSE
  )
mu1 <- number(as.numeric(tab_1[2, 2:4, TRUE]))
sd1 <- number(as.numeric(tab_1[4, 2:4, TRUE]))
mu1n <- tab_1[2, 2, TRUE]
sd1n <- tab_1[4, 2, TRUE]
```

We show a traditional summary of the estimated parameters from this model in Table \@ref(tab:tbl-fit-1). For the average person, the estimated effect of valence on RT is `r mu1[1]` log seconds, with a 95% bootstrap confidence interval (CI) extending from `r mu1[2]` to `r mu1[3]`. The estimated standard deviation of between-person differences in the valence effects is `r sd1[1]` log seconds, with a 95% CI of [`r sd1[2]`, `r sd1[3]`]. 

## Heterogeneity distribution

```{r descriptors, include = FALSE}
# Heterogeneity interval
hi90_num <- mu1n + qnorm(c(0.05, .95)) * sd1n
hi90 <- paste(
  number(hi90_num, .01),
  collapse = ", "
)
hi90_low <- paste(
  number(
    tab_1[2, 3, TRUE] + qnorm(c(0.05, .95)) * 
      tab_1[4, 3, TRUE], .01
  ),
  collapse = ", "
)

# Proportions
p_less_zero <- percent(pnorm(0, mu1n, sd1n), .1)
p_rope <- percent(pnorm(0.1, mu1n, sd1n) - pnorm(-0.1, mu1n, sd1n), .1)

# Ratio
ratio <- number(abs(sd1n / mu1n), .01)
```

```{r}
#| label: fig-1
#| fig.height: 2
#| fig.width: 8
#| fig.env: "figure*"
#| fig.align: "center"
#| fig.cap: Heterogeneity distribution of valence effects and various descriptions of their expected heterogeneity as estimated with Model 1. A. The normal density curve defined by the point estimates of the valence effect distribution's mean ($\beta_1$) and standard deviation ($\tau_1$). Shaded areas represent areas under the normal curve within 1 (dark) and 2 (light) standard deviations of the mean. B. The 90\% Heterogeneity Interval as represented by a line segment with arrows, and the dark shaded area. C. Proportion of negative valence effects in the population (dark). D. Proportion of valence effects in the population that are within the region of practical equivalence to zero (ROPE; dark).

fig_0 <- ggplot() +
  aes(xdist = dist_normal(mu1n, sd1n)) +
  scale_x_continuous(breaks = extended_breaks()) +
  coord_cartesian(xlim = c(-0.55, 0.25)) +
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_text(lineheight = rel(0.5))
  ) +
  scale_fill_manual(values = c("grey90", "grey80"), na.value = "white")
d1 <- dist_normal(mu1n, sd1n) |>
  mean_qi(.width = c(.66, .9))

fig_1 <- fig_0 +
  stat_slab(
    aes(fill = after_stat(level)),
    .width = c(.68, .95),
    p_limits = c(.000001, .999999),
    slab_color = "grey10",
    slab_linewidth = .4
  ) +
  geom_text(
    label = TeX("$\\tau_1$"),
    x = mu1n + .05, y = .175,
    size = 3,
    parse = TRUE
  ) +
  annotate(
    "segment",
    x = mu1n, xend = mu1n + sd1n, y = .1, yend = .1,
    linewidth = .35,
    arrow = arrow(length = unit(4, "pt"), type = "closed")
  ) +
  geom_text(
    label = TeX("$\\beta_1$"),
    x = mu1n - .05, y = .075,
    size = 3,
    parse = TRUE
  ) +
  annotate(
    "segment",
    x = mu1n, xend = mu1n, y = .1, yend = 0,
    linewidth = .35,
    arrow = arrow(length = unit(4, "pt"), type = "closed")
  ) +
  theme(axis.title.y = element_text(angle = 90))

fig_2 <- fig_0 +
  stat_slab(
    aes(fill = after_stat(level)),
    .width = c(.90, 1),
    p_limits = c(.000001, .999999),
    slab_color = "grey10",
    slab_linewidth = .4
  ) +
  geom_text(
    label = TeX("$HI_{90}$"),
    x = mu1n, y = .175,
    size = 3,
    parse = TRUE
  ) +
  annotate(
    "segment",
    x = d1$.lower[2], xend = d1$.upper[2], y = .1, yend = .1,
    linewidth = .35,
    arrow = arrow(length = unit(4, "pt"), type = "closed", ends = "both")
  )

fig_3 <- fig_0 +
  stat_slab(
    aes(fill = after_stat(x < 0)),
    p_limits = c(.000001, .999999),
    slab_color = "grey10",
    slab_linewidth = .4
  ) +
  geom_text(
    label = TeX("$p^d$"),
    x = mu1n, y = .175,
    size = 3,
    parse = TRUE
  )

fig_4 <- fig_0 +
  stat_slab(
    aes(fill = after_stat(between(x, -.1, .1))),
    p_limits = c(.000001, .999999),
    slab_color = "grey10",
    slab_linewidth = .4
  ) +
  geom_text(
    label = TeX("$p^{ROPE}$"),
    x = 0, y = .07,
    size = 3,
    parse = TRUE
  )

(fig_1 | fig_2 | fig_3 | fig_4) &
  scale_y_continuous(
    expand = expansion(c(0.0, 0.05))
  ) &
  labs(
    y = "Density",
    x = "Valence effect"
  ) &
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "none"
  ) &
  plot_annotation(tag_levels = "A")
```

The point estimates in Table \@ref(tab:tbl-fit-1) define the expected normal distribution of valence effects in the population, visualized in Figure \@ref(fig:fig-1)A. As such, Normal(`r mu1`, `r sd1`^2^) is a valid description of heterogeneity in valence effects. However, it is an incomplete description of heterogeneity for two reasons. First, it does not necessarily communicate the degree of heterogeneity in clear and actionable terms. Second, it ignores the uncertainty with which the heterogeneity parameters are estimated. 

### Interval descriptors

Having estimated the parameters of the heterogeneity distribution, we now turn to using them to define alternative, more informative descriptions of the degree of heterogeneity in valence effects in the population.

To begin with, and following @bolgerCausalProcessesPsychology2019, we used the point estimates in Table \@ref(tab:tbl-fit-1) to construct an expected *heterogeneity interval* that describes a range within which a certain percentage of the population's slopes are expected to fall. By convention, @bolgerCausalProcessesPsychology2019 and others have focused on the 95% heterogeneity interval ($HI_{95}$), but because there are already confusingly many quantities using the five percent cutoff, in this manuscript we focus on the 90% heterogeneity interval, and reserve 95% to describing uncertainties. 

To calculate a heterogeneity interval, we first specify the desired probability limits. For a 90% interval, we use the .05 and .95 percentiles (which define the central 90% of the distribution). Then, we pass those percentiles and the estimated mean and standard deviation (see Table \@ref(tab:tbl-fit-1)) to the normal quantile function ($q$; `qnorm()` in R) to obtain the interval: $HI_{90} = q([.05, .95], \beta_1, \tau_1) = q([.05, .95],$ `r mu1[1]`, `r sd1[1]`) = [`r hi90`]. In words, this equation calculates the 0.05 and 0.95 quantiles of the normal distribution defined by the mean's ($\beta_1$) and standard deviation's ($\tau_1$) point estimates: We expect 90% of valence effects in the population to fall within this interval. We illustrate this interval in Figure \@ref(fig:fig-1)B.

### Proportion descriptors

For many applications, quantities such as proportions of slopes above or below some critical value, or within some critical range, might serve as more informative summaries. For example, we might ask "What proportion of individuals in the population respond faster to positively valenced words?" Thus, we first define a critical value, here zero. We then pass that value and the valence effect's estimated mean and standard deviation to the cumulative normal distribution function ($p$; `pnorm()` in R) to obtain the probability density in this distribution that falls below zero: $p^d = p(0, \beta_1, \tau_1) = p(0,$ `r mu1`, `r sd1`) = `r p_less_zero`. Specifically, this metric indicates the proportion of individuals in the population with negative effects. In words, we have estimated that `r p_less_zero` of the population respond faster to positively valenced words. We show this area under the curve in Figure \@ref(fig:fig-1)C.

However, using zero as a critical value might not be sufficiently informative especially when theory allows defining a smallest effect sizes of interest, or what is known as a region of practical equivalence (to zero) [@anvariUsingAnchorbasedMethods2021; @kruschkeBayesianDataAnalysis2017; @kruschkeDoingBayesianData2014]. For example, we might know from theory that valence effects in the interval [-0.1, 0.1] are practically equivalent to zero. To calculate, we can again use the cumulative normal distribution function ($p$) to calculate the proportion of individuals in the population whose valence effect falls within this interval or region of practical equivalence: $p^{ROPE} = p(0.1, \beta_1, \tau_1) - p(-0.1, \beta_1, \tau_1)$ = `r p_rope`. In words, `r p_rope` of the population is expected to have valence effects that are practically equivalent to zero (within the [-0.1, 0.1] interval). We visualize this area under the curve in Figure \@ref(fig:fig-1)D.

### Ratio descriptors

Although the interval and proportion descriptors show where the population's slope values are likely to fall, they do so in absolute terms, such as log(rt) in the running example. A contrasting, relative way to show heterogeneity is to express it as a ratio of the standard deviation to the mean. In our example this is the ratio of the standard deviation to the mean of the valence effect.

[@bolgerCausalProcessesPsychology2019, p.609] suggest as a rule of thumb that if the ratio of the standard deviation to the average effect is 0.25 or greater, then heterogeneity can be deemed noteworthy. With these data and model, the ratio $\frac{\tau_1}{\beta_1}$ is `r ratio`, suggesting that the degree of heterogeneity in valence effects is noteworthy. (We reiterate the point made by @bolgerCausalProcessesPsychology2019 that the cutoff value of 0.25 is arbitrary and researchers should choose the cutoff based on their substantive goals.)

## Uncertainty

Although informative, the expected normal distribution of valence effects, or any transformation of those point estimates such as the ones illustrated in Figure \@ref(fig:fig-1), ignores the uncertainty inherent in the estimated parameters, and therefore cannot communicate the analyst's uncertainty about the degree of heterogeneity. That is, the uncertainty with which we have estimated the population parameters, indicated by e.g. the confidence intervals in Table \@ref(tab:tbl-fit-1), is not carried forward to the calculations described above. For example, we only presented the expected heterogeneity interval, but not the range of credible values that it might take. For instance, if we re-calculate $HI_{90}$ based on the lowest 95%CI bounds in Table \@ref(tab:tbl-fit-1), the result is a heterogeneity interval that indicates 90% of the population's slopes falling in the [`r hi90_low`] interval. In contrast to the first interval, this interval implies much less heterogeneity and that 90% of the population's slopes are expected to fall below zero. 

We have now arrived at the crux of the current work: How should we estimate and describe heterogeneity in psychological phenomena such that the fundamental uncertainty in the estimated parameters is retained?

# Probabilistic assessment of heterogeneity

We think that probabilistic (i.e. "bayesian") methods are uniquely applicable to estimating and describing heterogeneity in psychological phenomena in ways that naturally incorporate information about uncertainty because they deliver distributions of plausible values that could underlie hypothetical data generating processes [@gelmanBayesianDataAnalysis2013; @kruschkeBayesianDataAnalysis2017; @kruschkeDoingBayesianData2014; @mcelreathStatisticalRethinkingBayesian2020]. Moreover, these methods are widely available in modern software packages: For typical scenarios, probabilistic models are as easily estimated as their maximum likelihood counterparts.

```{r fit1-brms}
fit_1 <- brm(
  rt ~ 1 + valence + (1 + valence | person),
  data = dat,
  file = "models/brm-fit-1",
  control = list(adapt_delta = .95)
)
```

```{r}
#| label: ppcheck-1
#| eval: false

# Quick model checking
pairs(fit_1$fit, pars = variables(fit_1)[1:6])
mcmc_plot(fit_1, type = "rhat_hist")
pp_check(fit_1)
```

```{r}
#| label: tbl-fit-1-brms
#| cache: false

tab1 <- parameters(fit_1, centrality = "mean", effects = "all") |>
  tibble() |>
  select(Parameter, Mean, starts_with("CI_"))
```

```{r}
#| label: tbl-samples-1
#| cache: false

post1 <- as.data.frame(fit_1, variable = c("b_", "sd_", "cor_", "sigma"), regex = TRUE) |>
  tibble() |>
  rownames_to_column("Sample")
post1_sum <- fit_1 |>
  parameters(effects = "all", centrality = "mean", dispersion = TRUE) |>
  tibble() |>
  mutate(
    Mean = number(Mean, .01),
    SD = number(SD, .001)
  ) |>
  select(Parameter, Mean, SD) |>
  pivot_longer(c(Mean, SD), names_to = "Sample") |>
  pivot_wider(names_from = Parameter, values_from = value)

set.seed(191)
post1 |>
  slice_sample(n = 6) |>
  arrange(as.integer(Sample)) |>
  mutate(
    across(-Sample, ~ number(., .01))
  ) |>
  add_row(post1_sum) |>
  setNames(c("Sample", m1_parnames)) |>
  apa_table(
    span_text_columns = FALSE,
    font_size = "small",
    midrules = 6,
    caption = "Six random samples from Model 1's parameters' posterior distributions, and their summaries.",
    escape = FALSE,
    placement = "h"
  )
```

The goal of bayesian inference is the multivariate posterior probability distribution of the model's parameters. However, because closed-form solutions are not available for posterior distributions of many important types of statistical models, in practice bayesian methods rely on drawing many random samples from the posterior distribution [@gelmanBayesianDataAnalysis2013; @ravenzwaaijSimpleIntroductionMarkov2016]. Therefore, "estimate" means a large number of random samples from the posterior distribution. These samples can then be used to calculate, summarize, and visualize the posterior distribution of any desired quantity. 

In practice, one obtains (e.g.) 4,000 samples from the posterior distribution using computational algorithms [e.g. @standevelopmentteamStanModelingLanguage2023] through accessible software [e.g., @burknerBrmsPackageBayesian2017], and then summarizes them using familiar data processing techniques [e.g. @rcoreteamLanguageEnvironmentStatistical2023]. Here, we used the R package brms [@burknerBrmsPackageBayesian2017] to specify the model and then draw random samples from its posterior distribution [@standevelopmentteamStanModelingLanguage2023]. The MCMC estimation algorithm completed in about 2 minutes on a modern laptop. We then assessed the estimation algorithm convergence graphically and numerically, and model adequacy using a graphical posterior predictive check [@gelmanBayesianDataAnalysis2013].

Table \@ref(tab:tbl-samples-1) shows six random samples from Model 1's posterior distribution; the two bottom rows show their means and standard deviations. Note that because we used the brms package's default noninformative prior distributions, the posterior summaries are numerically very similar to the maximum likelihood estimates in Table \@ref(tab:tbl-fit-1). 

## Heterogeneity distribution

Armed with the bayesian estimates (Table \@ref(tab:tbl-samples-1)), we now return to the distribution of valence effects in the population. We first redraw the expected heterogeneity distribution from Figure \@ref(fig:fig-1) using the posterior mean values of $\beta_1$ and $\tau_1$ in Figure \@ref(fig:fig-2)A (thick dark blue curve). Superimposed on that normal density curve are heterogeneity distributions calculated not from the posterior means, but from 100 randomly sampled values from the joint posterior distribution of $\beta_1$ and $\tau_1$. From these curves we glean that the distribution of valence effects might well be narrower (i.e. less heterogeneity) or wider (more heterogeneity) than is suggested by the point estimates. 

<!-- TODO: Conceptually link this to Figure 1 Panel A -->

```{r}
#| label: calc-dfs

set.seed(99)
x <- seq(-0.6, 0.3, length = 301)

calculate_density <- function(posterior, b, sd) {
  posterior |>
    crossing(x) |>
    mutate(
      pdf = dnorm(x, {{b}}, {{sd}}),
      cdf = pnorm(x, {{b}}, {{sd}})
    )
}

post1_density_mean <- post1 |>
  mean_qi(b_valence1, sd_person__valence1) |>
  calculate_density(b_valence1, sd_person__valence1)

post1_density_samples <- post1 |>
  slice_sample(n = 100) |>
  calculate_density(b_valence1, sd_person__valence1)

post1_density_ribbon <- post1 |>
  select(b_valence1, sd_person__valence1) |>
  calculate_density(b_valence1, sd_person__valence1) |> 
  group_by(x) |>
  curve_interval(.width = 0.9)
```

```{r}
#| label: person-specific-valence-effects
#| eval: false

# Just sketching a figure of person-specific valence slopes
coef(fit_lmer)$person |> 
  as.data.frame() |> 
  rownames_to_column("person") |> 
  left_join(
    coef(fit_1)$person |> 
      as.data.frame() |> 
      rownames_to_column("person"),
    by = join_by(person)
) |> 
  select(person, MLE = valence1, Bayes = Estimate.valence1) |> 
  pivot_longer(-person) |> 
  ggplot(aes(value, name)) +
  geom_line(aes(group = person)) +
  geom_point()
summary(fit_1)
```

```{r}
#| label: fig-2
#| fig.height: 3
#| fig.width: 8
#| fig.env: "figure*"
#| fig.align: "center"
#| fig.cap: "Bayesian estimates of the heterogeneity distribution of valence effects. A. Probability density function (PDF) curves. The thick line illustrates the expected (point estimate; posterior mean) PDF of the valence effect heterogeneity distribution. Thin lines show 100 random samples of the PDF's posterior distribution, and facilitate visual communication of uncertainty in the PDF and, therefore, the valence effects' heterogeneity distribution. Dark line segments are inside the [-0.1, 0.1] ROPE, light segments are outside. The y-axis is in arbitrary probability density units at each point of the x-axis. B. The heterogeneity distribution's posterior mean PDF curve (line), and 90\\%CI (ribbon). C. Cumulative density function (CDF) curves, annotated as A. D. Histogram of the posterior distribution of $p^d$ (CDF segments below zero): This value describes the proportion of individuals with negative valence effects on logRT. Point and interval representes the posterior mean and 95\\%CI. E. As C, but represents uncertainty with a 95\\% confidence ribbon. F. Approximate posterior density of $p^d$."

# Shared Y axis
scale_y_01 <- scale_y_continuous(
  breaks = extended_breaks(7),
  expand = expansion(c(0.005, 0.005)),
  limits = c(0, 1)
)

# Posterior samples of pdf and cdf curves
p_cdf_samples <- post1_density_mean |>
  ggplot() +
  aes(x, cdf) +
  ylab("Cumulative density") +
  scale_color_manual(
    values = c("dodgerblue1", "dodgerblue4")
  ) +
  scale_x_continuous(
    "Valence effect",
    expand = expansion(0),
    breaks = extended_breaks()
  ) +
  scale_y_01 +
  geom_vline(
    xintercept = 0, 
    lty = "dotted", 
    linewidth = .25
  ) +
  geom_line(
    linewidth = .6,
    col = "dodgerblue4"
  ) +
  theme(legend.position = "none")

p_pdf_samples <- p_cdf_samples +
  aes(y = pdf) +
  geom_line(
    data = post1_density_samples,
    aes(group = Sample),
    col = "dodgerblue1",
    alpha = .33,
    linewidth = .15
  ) +
  scale_y_continuous(
    breaks = extended_breaks(7),
    expand = expansion(c(0.005, 0.005)),
  ) +
  ylab("Probability density") +
  theme(
    axis.title.x = element_blank()
  )

p_cdf_samples <- p_cdf_samples +
  geom_line(
    data = post1_density_samples,
    aes(group = Sample, color = after_stat(between(x, -0.1, 0.1))),
    alpha = .33,
    linewidth = .15
  )

# Posterior mean and 95%CI pdf and cdf curves
p_cdf_ribbon <- post1_density_ribbon |>
  ggplot(aes(x = x)) +
  aes(y = cdf, ymin = cdf.lower, ymax = cdf.upper) +
  scale_x_continuous(
    "Valence effect",
    expand = expansion(0),
    breaks = extended_breaks()
  ) +
  scale_y_continuous(
    breaks = extended_breaks(7),
    expand = expansion(c(0.005, 0.005))
  ) +
  geom_vline(
    xintercept = 0, 
    lty = "dotted", 
    linewidth = .25
  ) +
  geom_lineribbon(
    linewidth = .5,
    color = "dodgerblue4",
    fill = alpha("dodgerblue1", .33)
  ) +
  theme(
    legend.position = "none",
    axis.title.y = element_blank()
  )

p_pdf_ribbon <- p_cdf_ribbon +
  aes(y = pdf, ymin = pdf.lower, ymax = pdf.upper) +
  theme(
    axis.title.x = element_blank(), 
  )


# Add summaries of CDF < 0 to CDF curves as inset plots
p_p0 <- post1 |>
  mutate(dist = dist_normal(b_valence1, sd_person__valence1)) |>
  ggplot() +
  scale_x_continuous(
    expand = expansion(c(0.0, 0.1))
  ) +
  scale_y_01 +
  theme_void(base_size = 9) + 
  theme(
    plot.tag.position = c(.55, .75), 
    plot.tag = element_text(size = rel(1))
  )
p_p0_samples <- p_p0 + 
  stat_histinterval(
    aes(y = cdf(dist, 0)),
    breaks = 50,
    fill = alpha("dodgerblue1", 0.5),
    color = "dodgerblue4",
    side = "right",
    .width = .95,
    size = 1,
    scale = 0.5,
    justification = 0.025
  )
p_p0_density <- p_p0 + 
  stat_slabinterval(
    aes(y = cdf(dist, 0)),
    fill = alpha("dodgerblue1", 0.5),
    color = "dodgerblue4",
    side = "right",
    .width = .95,
    size = 1,
    scale = 0.5,
    justification = 0.025
  )
p_cdf_samples <- p_cdf_samples +
  inset_element(
    p_p0_samples,
    0, 0, .2, 1, 
    align_to = "panel", 
    on_top = TRUE
  )
p_cdf_ribbon <- p_cdf_ribbon +
  inset_element(
    p_p0_density,
    0, 0, .2, 1, 
    align_to = "panel", 
    on_top = TRUE
  )

p_cdf <- p_cdf_samples | p_cdf_ribbon

p_pdf <- p_pdf_samples | p_pdf_ribbon

(p_pdf / p_cdf) +
  plot_annotation(tag_levels = "A")
```

Moreover, the location of these curves differ: Some curves are further to the left (valence effect for the average person is more negative), and some further to the right (effect for the average person is more positive). The distribution of these curves represents our uncertainty over the heterogeneity distribution of valence effects in the population, and can be more completely summarized graphically as a ribbon: Figure \@ref(fig:fig-2)B shows the 95%CI of the valence effect's probability density for each value of the effect on the x-axis. A sufficient description of heterogeneity must include information about uncertainty in both the location (mean) and scale (standard deviation) parameters of the heterogeneity distribution.

However, depicting the heterogeneity distribution visually as a probability density function (PDF) curve has its drawbacks. First, it appears to us visually more challenging to read the degree of uncertainty from a PDF, even when the underlying parameters' uncertainty is summarized as an interval (Figure \@ref(fig:fig-2)B). Second, for many applications, the y-axis is not informative: We do not care that the probability density of the curve is (e.g.) 3.0 at some specific value of the valence effect.

Therefore, in Figure \@ref(fig:fig-2)C we depict the heterogeneity distribution as a *cumulative density* function (CDF). We again superimposed 100 random samples from the curve's posterior distribution on the posterior mean curve, and summarize the entire posterior distribution with a credibility ribbon in Figure \@ref(fig:fig-2)D. We believe the CDF is particularly useful as a descriptor of heterogeneity, because the y-axis specifically describes the proportion of population with valence effects below (or above) some specific value of the effect, as we highlight below.

### Interval descriptors

```{r}
p1n <- post1 |>
  mutate(
    hi_low = b_valence1 + qnorm(0.05) * sd_person__valence1,
    hi_high = b_valence1 + qnorm(0.95) * sd_person__valence1
  ) |>
  mean_qi(hi_low, hi_high)
p1s <- p1n |>
  mutate(
    across(where(is.numeric), ~ number(., .01)),
    l = str_glue("[{hi_low.lower}, {hi_low.upper}]"),
    u = str_glue("[{hi_high.lower}, {hi_high.upper}]")
  )
```

Above, we described the heterogeneity interval as a range of values where a specific percentage of the population's slopes are expected to fall (e.g. $HI_{90}$ for a 90% heterogeneity interval). However, a single interval cannot accommodate the uncertainty with which the underlying parameters are estimated. To carry uncertainty forward from model parameters to their transformations, such as the $HI_{90}$, we redo the calculations from above, but instead of using only the mean's and standard deviation's point estimates, we repeat the calculations for each of the 4,000 randomly sampled pairs of $\beta_1$ and $\tau_1$. Consequently, we get 4,000 samples from the $HI_{90}$s posterior distribution (Figure \@ref(fig:intervals)). 

Summarizing a distribution of intervals entails some challenges, however, because an interval is defined by two quantities---the lower and upper bounds. The 95% most credible lower bounds of $HI_{90}$ range between `r p1s$l`, whereas the 95% most credible upper bounds range between `r p1s$u` (Figure \@ref(fig:intervals)B). Thus, to adequately describe an estimated heterogeneity interval, researchers must communicate two separate uncertainty intervals: In words, we estimate that 90% of the population's valence effects range from `r paste(p1s$hi_low, p1s$l)` to `r paste(p1s$hi_high, p1s$u)`.

Figure \@ref(fig:intervals)A further suggests that communicating the two uncertainty intervals of a heterogeneity interval is not only cumbersome, but also ignores potential correlations between the heterogeneity interval endpoints' posterior distributions.

### Proportion descriptors

A complementary description of heterogeneity is the proportion of the population whose effects fall above or below some critical value. For example, we can calculate proportions with negative and positive effects by using zero as the critical value. In this example, we ask "What proportion of individuals in the population have negative effects of valence?" 

```{r}
tmp <- post1 |>
  mutate(
    dist = dist_normal(b_valence1, sd_person__valence1),
    pd = cdf(dist, 0),
    rope = cdf(dist, 0.1) - cdf(dist, -0.1),
    ratio = abs(sd_person__valence1 / b_valence1)
  ) |>
  mean_qi(pd, rope, ratio) |>
  mutate(
    pd_r = str_glue(
      "{percent(pd, .1)} [{percent(pd.lower, .1)}, {percent(pd.upper, .1)}]"
    ),
    pd_r_n = str_glue(
      "{percent(1-pd, .1)} [{percent(1-pd.upper, .1)}, {percent(1-pd.lower, .1)}]"
    ),
    rope_r = str_glue(
      "{percent(rope, .1)} [{percent(rope.lower, .1)}, {percent(rope.upper, .1)}]"
    ),
    rope_r_n = str_glue(
      "{percent(1-rope, .1)} [{percent(1-rope.upper, .1)}, {percent(1-rope.lower, .1)}]"
    ),
    ratio_r = str_glue(
      "{number(ratio, .01)} [{number(ratio.lower, .01)}, {number(ratio.upper, .01)}]"
    )
  )
```

To answer, we calculate the cumulative probability density at zero of $\operatorname{Normal}(\beta_1, \tau_1)$ for each posterior sample of $\beta_1$ and $\tau_1$. We show 100 random samples of the CDF in Figure \@ref(fig:fig-2)C with a vertical line superimposed at zero. The y-axis value where each CDF crosses zero on the x-axis indicates the population proportion of negative valence effects. 

Critically, we also show a histogram of all 4,000 posterior samples of that proportion in the top left margin of Figure \@ref(fig:fig-2)C, with the associated 95%CI: According to the model, the proportion of individuals in the population with negative valence effects is approximately `r percent(as.numeric(tmp$pd), .1)` (posterior mean), but could be as low as `r percent(as.numeric(tmp$pd.lower), .1)` or as high as `r percent(as.numeric(tmp$pd.upper), .1)` (with 95% confidence). Alternatively [@bolgerCausalProcessesPsychology2019, p.605-606], the model predicts that `r tmp$pd_r_n` of individuals in the population would show reversals of the valence effect. 

We can use the posterior distribution of the valence effect's heterogeneity in other useful manners too. For example, if theory has helped us define a smallest effect size of interest (SESOI) to determine a range of magnitudes that are "practically equivalent to zero" (ROPE), we can use the posterior distribution to quantify uncertainty in the proportion of individuals predicted to have such practically equivalent to zero valence effects. We colored the curves in Figure \@ref(fig:fig-2)C such that curve segments within [-0.1, 0.1] are highlighted with a darker color. Those darker line segments represent proportions of the population whose valence effect is practically equivalent to zero ($p^{ROPE}$). To quantify uncertainty in $p^{ROPE}$ we then aggregate the segments' to a mean and a 95%CI: `r tmp$rope_r` of individuals in the population have a valence effect that is practically equivalent to zero. We note that the ROPE of [-0.1, 0.1] here was arbitrary and picked just to illustrate the example.

So far, these examples have highlighted the importance of quantifying uncertainty in descriptions of heterogeneity. Had we only focused on the point estimates (posterior means), we might have misleadingly concluded that $p^d$ = `r percent(tmp$pd, .1)` and $p^{ROPE}$ = `r percent(tmp$rope, .1)`. However, with 95% confidence, these values might be as small as `r percent(tmp$pd.lower, .1)` and `r percent(tmp$rope.lower, .1)`, or as large as `r percent(tmp$pd.upper, .1)` and `r percent(tmp$rope.upper, .1)`, respectively.

### Ratio descriptors

Finally, we can assess heterogeneity in relative terms by comparing the magnitude of the heterogeneity in valence effects (the standard deviation $\tau_1$) to the magnitude of the average effect (the mean $\beta_1$) by calculating the ratio $\frac{\tau_1}{\beta_1}$. Figure \@ref(fig:hdist-5)A shows 4,000 samples from the joint posterior distribution of the mean and standard deviation, which we then transformed into 4,000 samples of the posterior distribution of $\frac{\tau_1}{\beta_1}$ in Figure \@ref(fig:hdist-5)B. The ratio `r tmp$ratio_r` suggests that the relative magnitude of heterogeneity is substantial, but might be as low as `r number(tmp$ratio.lower, .01)` or as great as `r number(tmp$ratio.upper, .01)`, with 95% confidence.

```{r}
#| label: hdist-5
#| fig.height: 2.2
#| fig.width: 4
#| fig.cap: Panel A. 4,000 random draws from the posterior distribution of the valence effect distribution's mean ($\beta_1$) and standard deviation ($\tau_1$). B. Histogram of 4,000 draws from the posterior distribution of the ratio of the valence distribution's scale over its  location $\frac{\tau_1}{\beta_1}$, and its posterior mean and 95\%CI.

p1 <- post1 |>
  ggplot(aes(b_valence1, sd_person__valence1)) +
  scale_y_continuous(
    TeX("$\\tau_1$")
  ) +
  scale_x_continuous(
    TeX("$\\beta_1$")
  ) +
  geom_point(
    shape = 1,
    col = "dodgerblue1",
    alpha = .25,
    size = .75
  )
p2 <- post1 |>
  mutate(ratio = abs(sd_person__valence1 / b_valence1)) |>
  ggplot(aes(ratio)) +
  scale_y_continuous(
    "Count",
    expand = expansion(0)
  ) +
  scale_x_continuous(
    TeX("$\\frac{\\tau_1}{\\beta_1}$"),
    breaks = extended_breaks()
  ) +
  stat_histinterval(
    breaks = 100,
    fill = alpha("dodgerblue1", 0.5),
    color = "dodgerblue4",
    .width = .95,
    size = 1,
    justification = 0.01
  ) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
  )
(p1 | p2) &
  theme(
    aspect.ratio = 1
  ) &
  plot_annotation(tag_levels = "A")
```

Throughout these examples, we have seen that---in these example data---our uncertainty in the estimated heterogeneity metrics is substantial: Point estimates provide at best incomplete descriptions of our current state of knowledge regarding heterogeneity in valence effects. While useful in its own right, next we see that incorporating uncertainty is not only useful but critical when we turn from describing heterogeneity in one population to comparing it across multiple populations.

# Comparing heterogeneity

Next, we move beyond assessing heterogeneity in one population to comparing degrees of heterogeneity across multiple populations of study units. To illustrate, we reanalyze a dataset from @mahVariabilitySubjectsFree2023 addressing differences in between person variability (heterogeneity) in memory performance between a free recall memory experiment and a cued recall memory experiment. In @mahVariabilitySubjectsFree2023's Experiment 3, 260 individuals studied a list of twenty target words. After a short break, participants then either freely recalled as many of the target words as they could (Free recall group, N = 123) or recalled as many target words as they could when prompted with related cue words (Cued recall group, N = 137). Thus, the Free and Cued recall tasks had different groups of participants but the same target words. We show a sample of their data in Table \@ref(tab:tab-dat2).

```{r data-mah-lindsay-3, include = FALSE}
# Experiment 3: task type is between-person
path <- "data/mah-lindsay-experiment-3.zip"
if (!file.exists(path)) {
  download.file(
    "https://files.ca-1.osf.io/v1/resources/pfhu9/providers/osfstorage/?zip=",
    destfile = path
  )
  unzip(path, exdir = str_remove(path, ".zip"), junkpaths = TRUE)
}

dat <- read_excel(
  "data/mah-lindsay-experiment-3/CuedVsFree_DRM_2022_Item_Data.xlsx"
) |>
  filter(!Exclude) |>
  mutate(
    person = factor(idnumber),
    task = factor(test_type, levels = c("FR", "CR"), labels = c("Free", "Cued")),
    accuracy
  ) |>
  select(person, task, target, accuracy) |>
  # Two observations were miscoded
  mutate(accuracy = if_else(accuracy == 2, 1, accuracy)) |> 
  arrange(task, person, target)
```

With a preregistered Pitman-Morgan test, @mahVariabilitySubjectsFree2023 found that participants who completed the cued recall task showed greater heterogeneity in memory performance than did the free recall group: The Cued:Free recall variance ratio was 1.33 (with a [1.14, 1.54] 95% bootstrap interval). @mahVariabilitySubjectsFree2023 also confirmed this result by comparing multilevel models that did and didn't allow for different between-person variabilities in memory ability for the two groups, and found similar results across three different experiments.

```{r tab-dat2}
dat |>
  slice(4:6, .by = task) |> 
  apa_table(
    span_text_columns = FALSE,
    font_size = "small",
    escape = FALSE,
    digits = 0,
    caption = "Six rows of example dataset 2 (Mah \\& Lindsay, 2023; Exp 3)."
  )
```

Here, we reproduce and extend those analyses to illustrate how our graphical and numerical descriptions of heterogeneity generalize to describing differences in heterogeneity. We ask three questions about between-task differences in heterogeneity: (1) To what extent is memory performance more variable between people in the cued recall task compared to the free recall task? (2) To what extent is memory performance variability between target words different across cued recall and free recall tasks? And (3) How consistent is target word heterogeneity across the two tasks: Are target words associated with good memory performance in cued recall experiments the same words that are associated with good memory performance in free recall experiments?

To answer these questions, we model the $i$th total recall accuracy in 1 to `r nrow(dat)`, of person $j$ in 1 to `r length(unique(dat$person))`, word $k$ in 1 to `r length(unique(dat$target))`, and task $m$ in {F (free recall), C (cued recall)} as Bernoulli distributed, where the probability of an accurate answer is determined by the rate parameter $\pi_{ijkm}$. As is common with generalized linear models, we model the rate parameter through a nonlinear link function. In this example, we use the cumulative normal density function ($\Phi$; "probit"), but other link functions are also available, such as the common logit. Consequently, it is the "linear predictor" $\eta$ that we then model as a linear combination of the predictors.

\begin{align*}
\tag{2}
\text{Accuracy}_{ijkm} &\sim \operatorname{Bernoulli}\left(\pi_{ijkm}\right) \\
\pi_{ijkm} &= \Phi\left(\eta_{ijkm}\right) \\
\eta_{ijkm} &= \beta_{m} + \gamma_{jm} + \delta_{km} \\
\gamma_{[m:F]} &\sim 
  \operatorname{Normal}\left(0, \tau_{\gamma_{[m:F]}} \right) \\
\gamma_{[m:C]} &\sim 
  \operatorname{Normal}\left(0, \tau_{\gamma_{[m:C]}} \right) \\
\begin{bmatrix} 
  \delta_{[m:F]} \\ \delta_{[m:C]}
\end{bmatrix} &\sim 
  \operatorname{MVN}\left(
  \begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} 
  \tau_{\delta_{[m:F]}} &\rho_\delta \\ 
  \rho_\delta &\tau_{\delta_{[m:C]}} 
\end{bmatrix}\right).
\end{align*}

This Model 2 of memory performance is similar to our Model 1 of valence effects above, but contains two sources of heterogeneity (persons, whose parameters we represent with $\gamma$, and target words, whose parameters we write with $\delta$). In addition, instead of coding the task type (free recall vs. cued recall) using predictor coding schemes such as contrast or dummy coding, we have index-coded task using subscripts $_{m:F}$ to stand for Free recall parameters, and $_{m:C}$ for parameters pertaining to the Cued recall task. This reparameterization is useful, because it allows us to quantify heterogeneity in memory performance separately for the two tasks, rather than for (if using contrast coding) the average task and their difference. Notice also that we model $\gamma$ using to independent normal distributions, and $\delta$ with a multivariate normal distribution. Because different persons participated in the two tasks, we cannot assess whether participant-specific abilities are correlated across the tasks. But we can assess this for target items, which were common across the tasks.

```{r fit-brms-ml3}
#| message: false

model <- bf(
  accuracy ~ 0 + task + 
    (1 | gr(person, by = task)) + 
    (0 + task | target) 
)
fit2 <- brm(
  model,
  family = bernoulli("probit"),
  data = dat,
  silent = 0,
  file = "models/brm-fit-ml3-target",
  control = list(adapt_delta = .95)
)
```

```{r}
#| label: ppcheck-2
#| eval: false

# Quick model checking
pairs(fit2$fit, pars = variables(fit2)[1:7])
mcmc_plot(fit2, type = "rhat_hist")
pp_check(fit2, type = "bars_grouped", group = "task", ndraws = 100)
```

We estimated the model as above by drawing 4,000 random samples from the posterior distribution [@burknerBrmsPackageBayesian2017]. We then confirmed graphically and numerically that the estimation algorithm had converged, and that the model performed adequately using a graphical posterior predictive check [@gelmanBayesianDataAnalysis2013]. We summarise the model's posterior distribution in Table \@ref(tab:tbl-samples-2).

```{r}
#| label: tbl-samples-2
#| cache: true

m2_parnames <- c(
  "$\\beta_{m:F}$", "$\\beta_{m:C}$",
  "$\\tau_{\\gamma_{m:F}}$", "$\\tau_{\\gamma_{m:C}}$",
  "$\\tau_{\\delta_{m:F}}$", "$\\tau_{\\delta_{m:C}}$",
  "$\\rho_\\delta$"
)

post2 <- as_draws_df(
  fit2, 
  variable = c("b_", "sd_", "cor_"), 
  regex = TRUE
) |> 
  select(-.iteration, -.chain) |> 
  relocate(.draw, .before = b_taskFree)

set.seed(191)
post2 |>
  slice_sample(n = 6) |>
  mutate(.draw = as.character(.draw)) |> 
  add_row(
    post2 |> 
      summarise_draws(
        Mean = ~mean(.),
        SD = ~sd(.)
      ) |> 
      pivot_longer(c(Mean, SD), names_to = ".draw") |>
      pivot_wider(names_from = variable, values_from = value)
  ) |> 
  setNames(c("Sample", m2_parnames)) |> 
  apa_table(
    span_text_columns = FALSE,
    font_size = "scriptsize",
    midrules = 6,
    digits = 2,
    caption = "Six random samples from Model 2's parameters' posterior distributions, and their summaries.",
    escape = FALSE,
    placement = "h"
  )
```

```{r}
#| label: calc-2-heterogeneity

# Calculate all heterogeneity metrics and differences
post2 <- post2 |> 
  mutate(
    # Persons
    dist_person_free = dist_normal(b_taskFree, `sd_person__Intercept:taskFree`),
    dist_person_cued = dist_normal(b_taskCued, `sd_person__Intercept:taskCued`),
    pd_person_free = 1 - cdf(dist_person_free, 0),
    pd_person_cued = 1 - cdf(dist_person_cued, 0),
    ratio_person_free = abs(`sd_person__Intercept:taskFree` / b_taskFree),
    ratio_person_cued = abs(`sd_person__Intercept:taskCued` / b_taskCued),
    hi_low_free = b_taskFree + qnorm(0.05) * `sd_person__Intercept:taskFree`,
    hi_high_free = b_taskFree + qnorm(0.95) * `sd_person__Intercept:taskFree`,
    hi_low_cued = b_taskCued + qnorm(0.05) * `sd_person__Intercept:taskCued`,
    hi_high_cued = b_taskCued + qnorm(0.95) * `sd_person__Intercept:taskCued`,
    # Differences
    b_difference = b_taskCued - b_taskFree,
    sd_person_difference = 
      `sd_person__Intercept:taskCued` - `sd_person__Intercept:taskFree`,
    pd_person_difference = pd_person_cued - pd_person_free,
    ratio_person_difference = ratio_person_cued - ratio_person_free,
    hi_low_difference = hi_low_cued - hi_low_free,
    hi_high_difference = hi_high_cued - hi_high_free,
    # Targets
    dist_target_free = dist_normal(b_taskFree, `sd_target__taskFree`),
    dist_target_cued = dist_normal(b_taskCued, `sd_target__taskCued`),
    pd_target_free = 1 - cdf(dist_target_free, 0),
    pd_target_cued = 1 - cdf(dist_target_cued, 0),
    ratio_target_free = abs(`sd_target__taskFree` / b_taskFree),
    ratio_target_cued = abs(`sd_target__taskCued` / b_taskCued),
    # Differences
    sd_target_difference = 
      `sd_target__taskCued` - `sd_target__taskFree`,
    pd_target_difference = pd_target_cued - pd_target_free,
    ratio_target_difference = ratio_target_cued - ratio_target_free,
    .before = starts_with("cor_")
  ) |> 
  select(-starts_with("dist_"))

post2_sum <- post2 |> 
  mutate(
    across(b_taskFree:b_taskCued, list(p = ~pnorm(.x)))
  ) |> 
  summarize_draws(
    mean, ~quantile2(.x, probs = c(0.025, 0.975))
  ) |> 
  mutate(
    x = str_glue("{number(mean, .01)} [{number(q2.5, .01)}, {number(q97.5, .01)}]")
  )
```

## Comparing between-person heterogeneity across tasks

Descriptively, we reproduced @mahVariabilitySubjectsFree2023's finding that participants' memory performance was more heterogeneous in the cued recall than in the free recall experiment (columns 4 and 5 in Table \@ref(tab:tbl-samples-2)). We show the relevant estimated quantities, and the implied heterogeneity distributions in Figure \@ref(fig:fig-2-person). 

The top panel of Figure \@ref(fig:fig-2-person)A illustrates the posterior distributions of memory performance for the average person in the free and cued recall tasks, and their difference (cued - free recall). Notice that all quantities in this model are in the probit space ("z-scores"): While recall performance was `r post2_sum$x[post2_sum$variable=="b_taskFree"]` and `r post2_sum$x[post2_sum$variable=="b_taskCued"]` in the free and cued recall conditions, respectively, in the probit space, they can be converted to probabilities, in which the quantities were `r post2_sum$x[post2_sum$variable=="b_taskFree_p"]` and `r post2_sum$x[post2_sum$variable=="b_taskCued"]`. However, this conversion does not work in general and we therefore restrict descriptions to probits in what follows.

Second, and more importantly, the second panel in Figure \@ref(fig:fig-2-person)A describes the posterior distributions of the between-person standard deviations in memory ability in the free and cued recall tasks, and their difference (cued - free recall). The third row of Figure \@ref(fig:fig-2-person)A shows the estimated proportions of individuals whose memory performance is above chance in the two tasks, and their difference. The model estimates the proportion of individuals who perform above chance to be `r post2_sum$x[post2_sum$variable=="pd_person_difference"]` greater in the cued than in the free recall task. 

Perhaps surprisingly, even though the absolute measures of heterogeneity differed greatly between the two recall tasks, the bottom panel of Figure \@ref(fig:fig-2-person)A shows that the degree of relative heterogeneity is identical across the two tasks. (We truncated the Ratio axis at [-10, 10] because estimates of the ratio are extreme for estimated distributions with very small average effects but large standard deviations. The difference in ratios is very uncertain partly for the same reason.)

Moreover, we depict the heterogeneity distributions---both as PDFs and CDFs---in Figure \@ref(fig:fig-2-person)B. These figures, especially the bottom panel, allow for a concise description of (differences in) heterogeneity in the two tasks: First, we see that the majority of the free recall CDF is to the left of the zero (chance) line, indicating that the majority of this population is predicted to perform worse than chance. This information is described in more detail in the small posterior densities and point-intervals on the left y-axis: The model predicts above-chance performance only for `r post2_sum$x[post2_sum$variable=="pd_person_free"]` of the population. Second, we see that the slope of the cued recall CDF is less steep than that of the free recall CDF: The between-person distribution of memory abilities is more dispersed in the cued than in the free recall task.

```{r}
#| label: fig-2-person-calc

x <- seq(-2.2, 2.2, length = 201)

tmp_person <- bind_rows(
  "Free" = post2 |>
    select(b_taskFree, `sd_person__Intercept:taskFree`) |>
    calculate_density(b_taskFree, `sd_person__Intercept:taskFree`) |> 
    select(x, pdf, cdf),
  "Cued" = post2 |>
    select(b_taskCued, `sd_person__Intercept:taskCued`) |>
    calculate_density(b_taskCued, `sd_person__Intercept:taskCued`) |> 
    select(x, pdf, cdf),
  .id = "Task"
)  |> 
  group_by(x, Task) |>
  curve_interval(.width = 0.9)
```

```{r}
#| label: model-2-ratio
#| include: false

# Some ratios are weird
post2 |> 
  select(
    starts_with("b_"), 
    starts_with("sd_person"), 
    starts_with("ratio_person"), 
    -ends_with("_difference")
  ) |> 
  select(
    contains("free")
  ) |> 
  filter(ratio_person_free > 10)
```

```{r}
#| label: fig-2-person
#| fig-width: 8
#| fig-height: 3.6
#| fig.env: "figure*"
#| fig.cap: "Estimated between-person heterogeneity in memory performance in Free recall and Cued recall tasks from Model 2. A. Histograms of 4,000 posterior draws from the model parameters and their transformations, with points and intervals showing posterior means and 95\\%CIs. Differences calculated as Cued - Free recall. B. Probability density (top) and cumulative density functions (bottom) of the two groups' heterogeneity distributions (green: free recall, red: cued recall). The densities, points, and intervals on the left y-axis of the bottom panel indicate approximate posterior densities, with means and 95\\%CIs, of the proportions of the populations with memory performance above chance."

p2_pars_person <- post2 |> 
  select(contains("b_") | contains("person")) |> 
  pivot_longer(everything()) |> 
  mutate(
    name = str_to_lower(name) |> 
      str_remove("_person") |> 
      str_remove("_intercept:task") |> 
      str_remove("task")
  ) |> 
  separate(name, c("type", "group")) |> 
  mutate(
    type = factor(
      type, 
      levels = c("b", "sd", "pd", "ratio"),
      labels = c("Mean", "SD", "Pr(Above chance)", "Ratio")
    ),
    group = factor(
      group,
      levels = c("free", "cued", "difference"),
      labels = c("Free", "Cued", "Difference")
    ) |> fct_rev(),
    value = if_else(type == "Ratio" & abs(value) > 10, NaN, value)
  ) |> 
  ggplot(aes(value, group, col = group, fill = group)) +
  scale_color_brewer(
    "Recall task",
    palette = "Dark2",
    aesthetics = c("color", "fill"),
    direction = -1
  ) +
  scale_y_discrete(
    expand = expansion(c(0.1, 0.25))
  ) +
  scale_x_continuous(
    "Parameter value",
    expand = expansion(0.025)
  ) +
  geom_vline(
    xintercept = 0, linewidth = .2, alpha = .25
  ) +
  stat_histinterval(
    slab_alpha = .25,
    breaks = 50,
    normalize = "panels",
    .width = .95,
    size = 1,
    justification = 0.01
  ) +
  facet_wrap("type", ncol = 1, scales = "free") +
  theme(
    legend.position = "none",
    axis.title.y = element_blank()
  )

p2_cdf_person <- tmp_person |> 
  ggplot(aes(x = x)) +
  aes(y = cdf, ymin = cdf.lower, ymax = cdf.upper, col = Task, fill = Task) +
  geom_vline(
    xintercept = 0, linewidth = .2, alpha = .25
  ) +
  scale_color_brewer(
    "Recall task",
    palette = "Dark2",
    aesthetics = c("color", "fill"),
    direction = -1
  ) +
  scale_x_continuous(
    TeX("$\\Phi(Pr(Correct))$"),
    expand = expansion(0.01),
    breaks = extended_breaks(5),
    sec.axis = sec_axis(
      name = "Proportion correct",
      trans = ~pnorm(.), 
      breaks = c(0.05, .1, .3, .5, .7, .9, .95),
      labels = c(".05", ".1", ".3", ".5", ".7", ".9", ".95")
    )
  ) +
  scale_y_continuous(
    breaks = extended_breaks(7),
    expand = expansion(c(0.005, 0.005))
  ) +
  ylab("CDF") +
  geom_ribbon(
    alpha = .2, col = NA
  ) +
  geom_line(
    linewidth = .5
  ) +
  theme(
    legend.position = "none",
    panel.border = element_rect(fill = NA)
  )

p2_pdf_person <- p2_cdf_person %+% 
  aes(y = pdf, ymin = pdf.lower, ymax = pdf.upper) +
  ylab("PDF")

p2_cdf_person_inset <- post2 |> 
  select(pd_person_free, pd_person_cued) |> 
  pivot_longer(everything()) |> 
  ggplot() +
  scale_y_01 +
  scale_x_continuous(
    expand = expansion(0)
  ) +
  scale_color_brewer(
    "Recall task",
    palette = "Dark2",
    aesthetics = c("color", "fill"),
    direction = -1
  ) +
  stat_slab(
    aes(y = value, fill = name),
    side = "right",
    .width = .95,
    size = 1,
    scale = 0.5,
    alpha = .2,
    justification = 0.025
  ) +
  stat_pointinterval(
    aes(y = value, col = name),
    side = "right",
    .width = .95,
    size = 1,
    justification = 0.025
  ) +
  theme_void() +
  theme(legend.position = "none")

p2_cdf_person <- p2_cdf_person +
  inset_element(
    p2_cdf_person_inset,
    0, 0, .2, 1, 
    align_to = "panel", 
    on_top = TRUE
  )

p2_pcdf_person <- p2_pdf_person / p2_cdf_person

(p2_pars_person | wrap_elements(full = p2_pcdf_person)) +
  plot_annotation(tag_levels = "A")
```

Finally, we return to the heterogeneity interval (HI). The $HI_{90}$'s lower bound in the free recall task is `r post2_sum$x[post2_sum$variable=="hi_low_free"]`, and `r post2_sum$x[post2_sum$variable=="hi_low_cued"]` in the cued recall task. While this 5th percentile of the heterogeneity distribution was not credibly different across the two tasks (`r post2_sum$x[post2_sum$variable=="hi_low_difference"]`), the 95th percentiles differed at the 95% credibility level (`r post2_sum$x[post2_sum$variable=="hi_high_difference"]`). Moreover, studying Figure \@ref(fig:fig-2-person)B closely makes another implication of the different standard deviations clear: While the average person likely has greater memory performance in the cued recall task, the model predicts that there are also more individuals with very poor performances in the cued recall condition.

## Comparing between-target heterogeneity across tasks

Naturally, heterogeneity across people is the more theoretically important phenomenon for psychologists. However, examining and understanding heterogeneity in other sampled units can be both theoretically and methodologically important. Without weighing in on this difference too strongly, for the sake of our example analyses we next turn to our second and third questions regarding potential differences and consistency in between-target word heterogeneity.

```{r}
#| label: fig-2-target-calc

x <- seq(-2.2, 2.2, length = 201)

tmp_target <- bind_rows(
  "Free" = post2 |>
    select(b_taskFree, sd_target__taskFree) |>
    calculate_density(b_taskFree, `sd_target__taskFree`) |> 
    select(x, pdf, cdf),
  "Cued" = post2 |>
    select(b_taskCued, `sd_target__taskCued`) |>
    calculate_density(b_taskCued, `sd_target__taskCued`) |> 
    select(x, pdf, cdf),
  .id = "Task"
)  |> 
  group_by(x, Task) |>
  curve_interval(.width = 0.9)
```

```{r}
#| label: fig-2-target
#| fig.width: 8
#| fig.height: 3.6
#| fig.env: "figure*"
#| fig.cap: "Estimated between-target word heterogeneity in memory performance in Free recall and Cued recall tasks from Model 2. A. Histograms of 4,000 posterior draws from the model parameters and their transformations, with points and intervals showing posterior means and 95\\%CIs. Differences calculated as Cued - Free recall. B. Probability density (top) and cumulative density functions (bottom) of the two tasks' heterogeneity distributions (green: free recall, red: cued recall). The densities, points, and intervals on the left y-axis of the bottom panel indicate approximate posterior densities, with means and 95\\%CIs, of the proportions of the populations with memory performance above chance. C. Posterior mean (dark), and 100 posterior draws (light) of the correlation between target words' proportions correct in the free (x-axis) and cued recall (y-axis) tasks. Ellipses indicate the 90th percentile of the bivariate normal distribution."

p2_pars_target <- post2 |> 
  select(contains("target")) |> 
  rename_with(
    ~str_to_lower(.) |> 
      str_remove("target_") |> 
      str_remove_all("_task")
  ) |> 
  pivot_longer(everything()) |> 
  separate(name, c("type", "group"), extra = "merge") |> 
  mutate(
    type = factor(
      type, 
      levels = c("sd", "pd", "ratio", "cor"),
      labels = c("SD", "Pr(Above chance)", "Ratio", "Cor(Free, Cued)")
    ),
    group = factor(
      group,
      levels = c("free", "cued", "difference", "free_cued"),
      labels = c("Free", "Cued", "Difference", "Correlation")
    ) |> fct_rev(),
    value = if_else(type == "Ratio" & abs(value) > 10, NaN, value)
  ) |> 
  ggplot(aes(value, group, color = group, fill = group)) +
  scale_color_manual(
    "Recall task",
    values = c(rep("#7570B3", 2), "#D95F02", "#1B9E77"),
    aesthetics = c("color", "fill")
  ) +
  scale_y_discrete(
    expand = expansion(c(0.1, 0.25))
  ) +
  scale_x_continuous(
    "Parameter value",
    expand = expansion(0.1)
  ) +
  geom_vline(
    xintercept = 0, linewidth = .2, alpha = .25
  ) +
  stat_histinterval(
    breaks = 50,
    normalize = "panels",
    .width = .95,
    size = 1,
    slab_alpha = 0.2,
    justification = 0.01
  ) +
  facet_wrap("type", ncol = 1, scales = "free") +
  theme(
    legend.position = "none",
    axis.title.y = element_blank()
  )

p2_cdf_target <- tmp_target |> 
  ggplot(aes(x = x)) +
  aes(y = cdf, ymin = cdf.lower, ymax = cdf.upper, col = Task, fill = Task) +
  geom_vline(
    xintercept = 0, linewidth = .2, alpha = .25
  ) +
  scale_color_brewer(
    "Recall task",
    palette = "Dark2",
    aesthetics = c("color", "fill"),
    direction = -1
  ) +
  scale_x_continuous(
    TeX("$\\Phi(Pr(Correct))$"),
    expand = expansion(0.01),
    breaks = extended_breaks(5),
    sec.axis = sec_axis(
      name = "Proportion correct",
      trans = ~pnorm(.), 
      breaks = c(0.05, .1, .3, .5, .7, .9, .95),
      labels = c(".05", ".1", ".3", ".5", ".7", ".9", ".95")
    )
  ) +
  scale_y_continuous(
    breaks = extended_breaks(7),
    expand = expansion(c(0.005, 0.005))
  ) +
  ylab("CDF") +
  geom_ribbon(
    alpha = .2, col = NA
  ) +
  geom_line(
    linewidth = .5
  ) +
  theme(
    legend.position = "none",
    panel.border = element_rect(fill = NA)
  )

p2_pdf_target <- p2_cdf_target %+% 
  aes(y = pdf, ymin = pdf.lower, ymax = pdf.upper) +
  ylab("PDF")

p2_cdf_target_inset <- post2 |> 
  select(pd_target_free, pd_target_cued) |> 
  pivot_longer(everything()) |> 
  ggplot() +
  scale_y_01 +
  scale_x_continuous(
    expand = expansion(0)
  ) +
  scale_color_brewer(
    "Recall task",
    palette = "Dark2",
    aesthetics = c("color", "fill"),
    direction = -1
  ) +
  stat_slab(
    aes(y = value, fill = name),
    side = "right",
    .width = .95,
    size = 1,
    scale = 0.5,
    alpha = .2,
    justification = 0.025
  ) +
  stat_pointinterval(
    aes(y = value, col = name),
    side = "right",
    .width = .95,
    size = 1,
    justification = 0.025
  ) +
  theme_void() +
  theme(legend.position = "none")

p2_cdf_target <- p2_cdf_target +
  inset_element(
    p2_cdf_target_inset,
    0, 0, .2, 1, 
    align_to = "panel", 
    on_top = TRUE
  )

p2_pcdf_target <-  p2_pdf_target / p2_cdf_target

# Ellipses
.ellipse <- function(data) {
  data |>
    mutate(
      e = pmap(
        list(
          cor_target__taskFree__taskCued,
          sd_target__taskFree,
          sd_target__taskCued,
          b_taskFree,
          b_taskCued
        ),
        ~ ellipse(
          x = ..1,
          scale = c(..2, ..3),
          centre = c(..4, ..5),
          level = .90
        ) |>
          as_tibble()
      )
    ) |>
    unnest(e)
}
samples <- as_draws_df(
  fit2,
  variable = c(
    "b_",
    "sd_",
    "cor_"
  ),
  regex = TRUE
)

set.seed(99)
ellipse_samples <- samples |>
  slice_sample(n = 100) |>
  .ellipse()

ellipse_median <- samples |>
  summarise_draws(median) |>
  pivot_wider(names_from = variable, values_from = median) |>
  .ellipse()

# Target word coefficients, data and model
dat2_target_coefs <- left_join(
  dat |> 
    summarise(
      p = qnorm(mean(accuracy)),
      .by = c(task, target)
    ) |> 
    pivot_wider(
      names_from = task, values_from = p
    ),
  coef(fit2)$target |> 
    as.data.frame() |> 
    rownames_to_column("target") |> 
    tibble() |> 
    select(
      target, 
      .Free = Estimate.taskFree,
      .Cued = Estimate.taskCued
    )
)

lims <- c(-1.8, 1.8)

p2_ellipse <- ellipse_median |>
  ggplot(aes(x, y)) +
  coord_cartesian(
    ylim = lims,
    xlim = lims
  ) +
  geom_vline(
    xintercept = 0, linewidth = .1, linetype = "dashed"
  ) +
  geom_hline(
    yintercept = 0, linewidth = .1, linetype = "dashed"
  ) +
  geom_abline(
    linewidth = .1, linetype = "dashed"
  ) +
  scale_x_continuous(
    TeX("$\\Phi(Pr(Correct))~Free~recall$"),
    breaks = seq(-1.5, 1.5, by = .5),
    sec.axis = sec_axis(
      trans = ~ pnorm(.),
      name = "Pr(Correct) Free recall",
      breaks = c(0.05, .1, .3, .5, .7, .9, .95),
      labels = c(".05", ".1", ".3", ".5", ".7", ".9", ".95")
    )
  ) +
  scale_y_continuous(
    TeX("$\\Phi(Pr(Correct))~Cued~recall$"),
    breaks = seq(-1.5, 1.5, by = .5),
    sec.axis = sec_axis(
      trans = ~ pnorm(.),
      name = "Pr(Correct) Cued recall",
      breaks = c(0.05, .1, .3, .5, .7, .9, .95),
      labels = c(".05", ".1", ".3", ".5", ".7", ".9", ".95")
    )
  ) +
  geom_path(
    data = ellipse_samples,
    aes(group = .draw),
    alpha = .075, color = "#7570B3"
  ) +
  geom_path(
    color = "#7570B3"
  ) +
  # geom_segment(
  #   data = dat2_target_coefs,
  #   aes(x = Free, xend = .Free, y = Cued, yend = .Cued)
  # ) +
  # geom_point(
  #   data = dat2_target_coefs,
  #   aes(x = Free, y = Cued),
  #   shape = 21, fill = "white"
  # ) +
  # geom_point(
  #   data = dat2_target_coefs,
  #   aes(x = .Free, y = .Cued),
  #   color = "dodgerblue4"
  # ) +
  theme(
    aspect.ratio = 1
  )

(wrap_elements(full = p2_pars_target) | wrap_elements(full = p2_pcdf_target) | p2_ellipse) +
  plot_annotation(tag_levels = "A")
```

The results regarding differences in memory performance heterogeneity across target words were similar to those as observed regarding heterogeneity in people's memory performances. Figure \@ref(fig:fig-2-target)A shows that heterogeneity (standard deviations) in memory performance was greater when words appeared in the cued recall task. The interpretation of this difference is quantitatively similar to that observed about people above: Units of study exhibit greater memory task performance variability in the cued recall than in the free recall task. However, because this experiment used the same target words across the two tasks, this interpretation is subtly more complex: This difference holds even when the exact same units---target words, in this example---are used in the two different tasks.

Moreover, we observe similar differences in between-target word heterogeneity between the two tasks' as we did in the above analysis of between-person heterogeneity: The model predicts a greater proportion of words to elicit greater than chance performance in the cued recall than in the free recall task. Yet, the ratio of the standard deviation to the mean again appeared identical across the two tasks.

However, this analysis of target word heterogeneity afforded an additional piece of information: There was a clear positive correlation between free and cued recall memory performance (bottom panel of Figure \@ref(fig:fig-2-target)B, and Figure \@ref(fig:fig-2-target)C). The posterior mean and 95%CI of this correlation was `r post2_sum$x[post2_sum$variable=="cor_target__taskFree__taskCued"]`. What this correlation means substantively is that words that are likely better recalled in the free recall task are also likely to be those that are better recalled in the cued recall task. @bolgerCausalProcessesPsychology2019 found the conceptually similar result within a correlation of random effects that individuals whose valence effect was stronger at Time 1 were also those whose valence effect was likely to be stronger at Time 2, one week later.

Although outside our current scope, we note that these analyses might indicate exciting new avenues for this line of inquiry. One explanation for the between-person heterogeneity difference is that participants might adopt different strategies for remembering in the two different recall tasks [@mahVariabilitySubjectsFree2023]. Our additional results suggest that such a mechanism may not be a complete account of differences in memory performance heterogeneity: Target words are presumably invariant regarding memory strategies, yet we find that recall accuracy is more heterogeneous across target words in the cued recall task than in the free recall task (columns 6 and 7 in Table \@ref(tab:tbl-samples-2); top panel in Figure \@ref(fig:fig-2-target)A). Further, we observed across two kinds of study units (people, target words) that the ratio of the between-unit standard deviation to the average effect was nearly identical across the free and cued recall tasks.

# Discussion

In the current work, we illustrated the use of practical descriptors of heterogeneity in psychological phenomena with examples drawn from the published literature in both social and cognitive psychology. Our aim was to incrementally build on the work of @bolgerCausalProcessesPsychology2019, who described the importance and available methods for examining heterogeneity in causal effects in psychology, and describe how it is both critically important and practically feasible to incorporate uncertainty in analyses and descriptions of heterogeneity. We believe our currently proposed methods to be particularly useful to researchers because they allow doing just that: Incorporating uncertainty in the analyses at every stage, from modelling to communicating resulting inferences. 

- Researchers already focusing on heterogeneity
- awesome and my comments
- coin flipping (standard deviations reported but not inferential quantities (e.g. pr positive))
- in light of what we've presented they are not communicated in sufficient detail

Moreover, we emphasized throughout that probabilistic modelling allows carrying uncertainty forward from model parameters to heterogeneity descriptors. The resulting metrics are useful because they not only convey the analyst's expectation of the magnitude of heterogeneity, but also her uncertainty in the description. In addition, probabilistic modelling, by returning a matrix of samples from the posterior distribution, allows easily comparing these heterogeneity descriptors across groups.

We believe that psychology should take a meta-theoretic step forward and try to incorporate an understanding of heterogeneity into substantive theories [@bolgerCausalProcessesPsychology2019]. In order to do so, descriptions of heterogeneity must include measures of uncertainty.

## Practical implementation

We provide all the code supporting this manuscript at [todo]. There, we implement the graphical and computational methods for investigating heterogeneity presented here in the R programming language [@rcoreteamLanguageEnvironmentStatistical2023]. Moreover, we make use of the ecosystem of R packages for bayesian computation, including brms [@burknerBrmsPackageBayesian2017; @burknerAdvancedBayesianMultilevel2018] and ggdist [@ggdist2023]. 

## Limitations

- We assume gaussian distributions but see rouder

## Conclusion

# Data and code availability

All the code supporting this manuscript is available at <https://github.com/mvuorre/heterogeneity-uncertainty> and archived on Zenodo at [todo]. We reused openly available data from @bolgerCausalProcessesPsychology2019 and @mahVariabilitySubjectsFree2023.

# Author contributions

<!-- https://casrai.org/credit/ -->

Conceptualization: MV, NB\
Formal Analysis: MV\
Methodology: MV, NB, MK\
Project Administration: MV\
Software: MV, MK\
Visualization: MV, MK, NB\
Writing  Original Draft: MV\
Writing  Review & Editing: MV, NB, MK

# Competing interests

The author(s) declare no competing interests.

# References {-}

::: {#refs custom-style="Bibliography"}
:::


<!-- Prepare appendix section -->
\clearpage
\setcounter{page}{1}
\setcounter{table}{0}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\thefigure}{A\arabic{figure}}
\onecolumn

# Appendix

```{r}
#| label: intervals
#| fig.height: 2.4
#| fig.width: 8
#| fig.cap: Bayesian estimates of the 90% heterogeneity interval of valence effects. A. Scatterplot of 4,000 posterior samples of the lower (x-axis) and upper (y-axis) limits of the $HI_{90}$. B. Histograms of 4,000 samples of the HI90 lower (left) and upper (right) limits with their posterior means and 95%CIs as points and intervals. C. 100 random samples from the $HI_{90}$ posterior distribution, with the posterior mean heterogeneity interval superimposed in a darker shade of blue.

p1 <- post1 |>
  mutate(
    hi_low = b_valence1 + qnorm(0.05) * sd_person__valence1,
    hi_high = b_valence1 + qnorm(0.95) * sd_person__valence1
  ) |>
  ggplot(aes(hi_low, hi_high)) +
  labs(x = "HI90 lower limit", y = "HI90 upper limit") +
  geom_point(
    alpha = .25,
    shape = 1,
    size = 0.75,
    col = "dodgerblue1"
  ) +
  theme(aspect.ratio = 1)

p2 <- post1 |>
  mutate(
    hi_low = b_valence1 + qnorm(0.05) * sd_person__valence1,
    hi_high = b_valence1 + qnorm(0.95) * sd_person__valence1
  ) |>
  select(Sample, hi_low, hi_high) |>
  pivot_longer(-Sample) |>
  ggplot(aes(value, group = name)) +
  scale_y_continuous(
    expand = expansion(c(0, 0.1))
  ) +
  scale_x_continuous(
    "Valence effects"
  ) +
  stat_histinterval(
    breaks = 100,
    fill = alpha("dodgerblue1", .33),
    color = "dodgerblue4",
    .width = c(.95),
    justification = .01
  ) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

p3 <- distinct(post1_density_samples, Sample, b_valence1, sd_person__valence1) |>
  arrange(b_valence1) |>
  mutate(i = 1:n()) |>
  mutate(
    dist = dist_normal(b_valence1, sd_person__valence1)
  ) |>
  ggplot() +
  scale_x_continuous(
    "Valence effect",
    expand = expansion(0.025),
    breaks = extended_breaks()
  ) +
  scale_y_continuous(
    expand = expansion(0.025)
  ) +
  labs(y = "Posterior sample") +
  stat_pointinterval(
    aes(xdist = dist, y = i),
    .width = .9,
    interval_size_range = c(.15, .3),
    alpha = .5,
    color = "dodgerblue1"
  ) +
  geom_pointinterval(
    data = post1 |>
      summarise(
        across(c(b_valence1, sd_person__valence1), mean)
      ) |>
      mutate(
        hi_low = b_valence1 + qnorm(0.05) * sd_person__valence1,
        hi_high = b_valence1 + qnorm(0.95) * sd_person__valence1
      ),
    aes(y = 50, x = b_valence1, xmin = hi_low, xmax = hi_high),
    color = "dodgerblue4"
  )

(p1 | p2 | p3) +
  # coord_cartesian(xlim = c(-0.6, 0.3)) &
  # scale_x_continuous(
  #   "Valence effect",
  #   expand = expansion(0),
  #   breaks = extended_breaks(7)
  # )) +
  # plot_layout(widths = c(6, 4)) +
  plot_annotation(tag_levels = "A")
```
