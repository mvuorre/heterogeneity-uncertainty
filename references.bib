@Book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Andrew Gelman and Jennifer Hill},
  date = {2007},
  publisher = {{Cambridge University Press}},
  location = {{New York, NY}},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/\textasciitilde gelman/arm/},
  isbn = {978-0-521-68689-1},
  langid = {english},
  pagetotal = {654},
  keywords = {_tablet,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Regression Analysis,Political Science / General,Psychology / Assessment; Testing & Measurement,Statistics},
  annotation = {00058},
}
@Book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {Richard McElreath},
  date = {2020},
  series = {{{CRC}} Texts in Statistical Science},
  edition = {2},
  publisher = {{Taylor and Francis, CRC Press}},
  location = {{Boca Raton}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
  isbn = {978-0-367-13991-9},
  langid = {english},
  keywords = {_tablet},
}
@Article{bolgerCausalProcessesPsychology2019,
  ids = {bolgerCausalProcessesPsychology},
  title = {Causal Processes in Psychology Are Heterogeneous.},
  author = {Niall Bolger and Katherine S. Zee and Maya Rossignac-Milon and Ran R. Hassin},
  date = {2019-04},
  journaltitle = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {4},
  pages = {601--618},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000558},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000558},
  urldate = {2019-04-25},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology.},
  langid = {english},
}
@Article{scholerInflatingDeflatingSelf2014,
  title = {Inflating and Deflating the Self: {{Sustaining}} Motivational Concerns through Self-Evaluation},
  shorttitle = {Inflating and Deflating the Self},
  author = {Abigail A. Scholer and Yuka Ozaki and E. Tory Higgins},
  date = {2014-03-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {51},
  pages = {60--73},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2013.11.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0022103113001947},
  urldate = {2023-03-17},
  abstract = {The ways in which individuals think and feel about themselves play a significant role in guiding behavior across many domains in life. The current studies investigate how individuals may shift the positivity of self-evaluations in order to sustain their chronic or momentary motivational concerns. Specifically, we propose that more positive self-evaluations support eagerness that sustains promotion-focused concerns with advancement, whereas less positive self-evaluations support vigilance that sustains prevention-focused concerns with safety. The current studies provide evidence that self-evaluation inflation is associated with promotion concerns whereas self-evaluation deflation is associated with prevention concerns, whether regulatory focus is situationally manipulated (Studies 1, 2b, and 3) or measured as a chronic individual difference (Study 2a). Following regulatory focus primes, individuals in a promotion focus showed relatively greater accessibility of positive versus negative self-knowledge compared to individuals in a prevention focus (Study 1). In an ongoing performance situation, participants in a promotion focus reported higher self-esteem than participants in a prevention focus (Studies 2a and 2b). Finally, individuals in a promotion focus persisted longer on an anagram task when given an opportunity to focus on their strengths versus weaknesses, which was not the case for individuals in a prevention focus (Study 3). Across studies, the predicted interactions were consistently obtained, although sometimes the effects were stronger for promotion or prevention motivation. We discuss implications for existing models of the motives underlying self-evaluation.},
  langid = {english},
  keywords = {Motivation,Prevention focus,Promotion focus,Regulatory fit,Regulatory focus,Self-evaluation,Self-regulation},
}
@Article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Paul-Christian B{\"u}rkner},
  date = {2018},
  journaltitle = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395--411},
  issn = {2073-4859},
  url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
  urldate = {2019-03-25},
  langid = {english},
}

@Article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  author = {Paul-Christian B{\"u}rkner},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  keywords = {Statistics},
  annotation = {00000},
}

@Software{rcoreteamLanguageEnvironmentStatistical2022,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}. {{Version}} 4.2.2},
  author = {{R Core Team}},
  date = {2022},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}},
  version = {4.2.2},
  keywords = {\#nosource},
}

@Article{batesFittingLinearMixedEffects2015,
  title = {Fitting {{Linear Mixed-Effects Models Using}} Lme4},
  author = {Douglas M. Bates and Martin M{\"a}chler and Ben M. Bolker and Steve Walker},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  keywords = {\#nosource,Statistics},
  annotation = {00014},
}
@Article{rabeHyprPackageHypothesisdriven2020,
  title = {Hypr: {{An R}} Package for Hypothesis-Driven Contrast Coding},
  shorttitle = {Hypr},
  author = {Maximilian M. Rabe and Shravan Vasishth and Sven Hohenstein and Reinhold Kliegl and Daniel J. Schad},
  date = {2020-04-27},
  journaltitle = {Journal of Open Source Software},
  volume = {5},
  number = {48},
  pages = {2134},
  issn = {2475-9066},
  doi = {10.21105/joss.02134},
  url = {https://joss.theoj.org/papers/10.21105/joss.02134},
  urldate = {2023-03-23},
  abstract = {Rabe et al., (2020). hypr: An R package for hypothesis-driven contrast coding. Journal of Open Source Software, 5(48), 2134, https://doi.org/10.21105/joss.02134},
  langid = {english},
}

@Article{schadHowCapitalizePriori2020,
  title = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: {{A}} Tutorial},
  shorttitle = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models},
  author = {Daniel J. Schad and Shravan Vasishth and Sven Hohenstein and Reinhold Kliegl},
  date = {2020-02-01},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {110},
  pages = {104038},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2019.104038},
  url = {https://www.sciencedirect.com/science/article/pii/S0749596X19300695},
  urldate = {2023-03-23},
  abstract = {Factorial experiments in research on memory, language, and in other areas are often analyzed using analysis of variance (ANOVA). However, for effects with more than one numerator degrees of freedom, e.g., for experimental factors with more than two levels, the ANOVA omnibus F-test is not informative about the source of a main effect or interaction. Because researchers typically have specific hypotheses about which condition means differ from each other, a priori contrasts (i.e., comparisons planned before the sample means are known) between specific conditions or combinations of conditions are the appropriate way to represent such hypotheses in the statistical model. Many researchers have pointed out that contrasts should be ``tested instead of, rather than as a supplement to, the ordinary `omnibus' F test'' (Hays, 1973, p. 601). In this tutorial, we explain the mathematics underlying different kinds of contrasts (i.e., treatment, sum, repeated, polynomial, custom, nested, interaction contrasts), discuss their properties, and demonstrate how they are applied in the R System for Statistical Computing (R Core Team, 2018). In this context, we explain the generalized inverse which is needed to compute the coefficients for contrasts that test hypotheses that are not covered by the default set of contrasts. A detailed understanding of contrast coding is crucial for successful and correct specification in linear models (including linear mixed models). Contrasts defined a priori yield far more useful confirmatory tests of experimental hypotheses than standard omnibus F-tests. Reproducible code is available from https://osf.io/7ukf6/.},
  langid = {english},
  keywords = {A priori hypotheses,Contrasts,Linear models,Null hypothesis significance testing},
}
@Book{gelmanBayesianDataAnalysis2013,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Andrew Gelman and John B. Carlin and Hal S. Stern and David B. Dunson and Aki Vehtari and Donald B. Rubin},
  date = {2013-11-01},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash all leaders in the statistics community\textemdash introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  isbn = {978-1-4398-4095-5},
  langid = {english},
  pagetotal = {677},
  keywords = {_tablet,bayesian statistics,Computers / Mathematical & Statistical Software,Mathematics / Probability & Statistics / General,Psychology / Research & Methodology,Statistics},
  annotation = {00000},
}

@Article{kruschkeBayesianDataAnalysis2017,
  title = {Bayesian Data Analysis for Newcomers},
  author = {John K. Kruschke and Torrin M. Liddell},
  date = {2017-04-12},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  pages = {1--23},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1272-1},
  url = {https://link.springer.com/article/10.3758/s13423-017-1272-1},
  urldate = {2017-04-13},
  abstract = {This article explains the foundational concepts of Bayesian data analysis using virtually no mathematical notation. Bayesian ideas already match your intuitions from everyday reasoning and from traditional data analysis. Simple examples of Bayesian data analysis are presented that illustrate how the information delivered by a Bayesian analysis can be directly interpreted. Bayesian approaches to null-value assessment are discussed. The article clarifies misconceptions about Bayesian methods that newcomers might have acquired elsewhere. We discuss prior distributions and explain how they are not a liability but an important asset. We discuss the relation of Bayesian data analysis to Bayesian models of mind, and we briefly discuss what methodological problems Bayesian data analysis is not meant to solve. After you have read this article, you should have a clear sense of how Bayesian data analysis works and the sort of information it delivers, and why that information is so intuitive and useful for drawing conclusions from data.},
  langid = {english},
  keywords = {Statistics},
  annotation = {00000},
}

@Book{kruschkeDoingBayesianData2014,
  title = {Doing {{Bayesian Data Analysis}}: {{A Tutorial Introduction}} with {{R}}},
  shorttitle = {Doing {{Bayesian Data Analysis}}},
  author = {John K. Kruschke},
  date = {2014},
  edition = {2nd Edition},
  publisher = {{Academic Press}},
  location = {{Burlington, MA}},
  abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis, A Tutorial Introduction with R and BUGS, provides an accessible approach to Bayesian Data Analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. The text delivers comprehensive coverage of all scenarios addressed by non-Bayesian textbooks- t-tests, analysis of variance (ANOVA) and comparisons in ANOVA, multiple regression, and chi-square (contingency table analysis). This book is intended for first year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Prerequisite is knowledge of algebra and basic calculus. Free software now includes programs in JAGS, which runs on Macintosh, Linux, and Windows. Author website: http://www.indiana.edu/\textasciitilde kruschke/DoingBayesianDataAnalysis/Provides complete examples with R programming language and BUGS software (both Freeware)  Addresses topics such as experiment planning, power analysis and sample size planning Includes numerous exercises with explicit purposes and guidelines for accomplishment.},
  isbn = {978-0-12-381486-9},
  langid = {english},
  pagetotal = {673},
  keywords = {_tablet,Mathematics / Applied,Mathematics / General,Mathematics / Probability & Statistics / Bayesian Analysis,Mathematics / Probability & Statistics / General,r,stan,Statistics},
  annotation = {00000},
}
