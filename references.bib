@article{anvariUsingAnchorbasedMethods2021,
  title = {Using Anchor-Based Methods to Determine the Smallest Effect Size of Interest},
  author = {Anvari, Farid and Lakens, Dani\"el},
  date = {2021-09-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {96},
  pages = {104159},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2021.104159},
  url = {https://www.sciencedirect.com/science/article/pii/S0022103121000627},
  urldate = {2021-09-30},
  abstract = {Effect sizes are an important outcome of quantitative research, but few guidelines exist that explain how researchers can determine which effect sizes are meaningful. Psychologists often want to study effects that are large enough to make a difference to people's subjective experience. Thus, subjective experience is one way to gauge the meaningfulness of an effect. We propose and illustrate one method for how to quantify the smallest subjectively experienced difference\textemdash the smallest change in an outcome measure that individuals consider to be meaningful enough in their subjective experience such that they are willing to rate themselves as feeling different\textemdash using an anchor-based method with a global rating of change question applied to the positive and negative affect scale. We provide a step-by-step guide for the questions that researchers need to consider in deciding whether and how to use the anchor-based method, and we make explicit the assumptions of the method that future research can examine. For researchers interested in people's subjective experiences, this anchor-based method provides one way to specify a smallest effect size of interest, which allows researchers to interpret observed results in terms of their theoretical and practical significance.},
  langid = {english},
  keywords = {Minimum important difference,Negative affect,Positive affect,Practical significance,Smallest effect size of interest,Smallest subjectively experienced difference,Subjectively experienced difference}
}

@article{batesFittingLinearMixedEffects2015,
  title = {Fitting {{Linear Mixed-Effects Models Using}} Lme4},
  author = {Bates, Douglas M. and M\"achler, Martin and Bolker, Ben M. and Walker, Steve},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  keywords = {\#nosource,Statistics},
  annotation = {00014}
}

@article{bolgerCausalProcessesPsychology2019,
  ids = {bolgerCausalProcessesPsychology},
  title = {Causal Processes in Psychology Are Heterogeneous.},
  author = {Bolger, Niall and Zee, Katherine S. and Rossignac-Milon, Maya and Hassin, Ran R.},
  date = {2019-04},
  journaltitle = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {4},
  pages = {601--618},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000558},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000558},
  urldate = {2019-04-25},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology.},
  langid = {english}
}

@incollection{brandCausalEffectHeterogeneity2013,
  title = {Causal {{Effect Heterogeneity}}},
  booktitle = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  author = {Brand, Jennie E. and Thomas, Juli Simon},
  editor = {Morgan, Stephen L.},
  date = {2013},
  pages = {189--213},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-94-007-6094-3_11},
  url = {http://link.springer.com/10.1007/978-94-007-6094-3_11},
  urldate = {2023-05-16},
  abstract = {Individuals differ not only in background characteristics, often called ``pretreatment heterogeneity,'' but also in how they respond to a particular treatment, event, or intervention. A principal interaction of interest for questions of selection into treatment and causal inference in the social sciences is between the treatment and the propensity of treatment. Although the importance of ``treatment-effect heterogeneity,'' so defined, has been widely recognized in the causal inference literature, empirical quantitative social science research has not fully absorbed these lessons. In this chapter, we describe key estimation strategies for the study of heterogeneous treatment effects; we discuss recent research that attends to causal effect heterogeneity, with a focus on the study of effects of education, and what we gain from such attention; and we demonstrate the methods with an example of the effects of college on civic participation. The primary goal of this chapter is to encourage researchers to routinely examine treatment-effect heterogeneity with the same rigor they devote to pretreatment heterogeneity.},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  langid = {english}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {B\"urkner, Paul-Christian},
  date = {2018},
  journaltitle = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395--411},
  issn = {2073-4859},
  url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
  urldate = {2019-03-25},
  langid = {english}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  author = {B\"urkner, Paul-Christian},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  keywords = {Statistics},
  annotation = {00000}
}

@book{gelmanBayesianDataAnalysis2013,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  date = {2013-11-01},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash all leaders in the statistics community\textemdash introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  isbn = {978-1-4398-4095-5},
  langid = {english},
  pagetotal = {677},
  keywords = {\_tablet,bayesian statistics,Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology,Statistics},
  annotation = {00000}
}

@book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  date = {2007},
  publisher = {{Cambridge University Press}},
  location = {{New York, NY}},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/\textasciitilde gelman/arm/},
  isbn = {978-0-521-68689-1},
  langid = {english},
  pagetotal = {654},
  keywords = {\_tablet,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Regression Analysis,Political Science / General,{Psychology / Assessment, Testing \& Measurement},Statistics},
  annotation = {00058}
}

@article{kruschkeBayesianDataAnalysis2017,
  title = {Bayesian Data Analysis for Newcomers},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  date = {2017-04-12},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  pages = {1--23},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1272-1},
  url = {https://link.springer.com/article/10.3758/s13423-017-1272-1},
  urldate = {2017-04-13},
  abstract = {This article explains the foundational concepts of Bayesian data analysis using virtually no mathematical notation. Bayesian ideas already match your intuitions from everyday reasoning and from traditional data analysis. Simple examples of Bayesian data analysis are presented that illustrate how the information delivered by a Bayesian analysis can be directly interpreted. Bayesian approaches to null-value assessment are discussed. The article clarifies misconceptions about Bayesian methods that newcomers might have acquired elsewhere. We discuss prior distributions and explain how they are not a liability but an important asset. We discuss the relation of Bayesian data analysis to Bayesian models of mind, and we briefly discuss what methodological problems Bayesian data analysis is not meant to solve. After you have read this article, you should have a clear sense of how Bayesian data analysis works and the sort of information it delivers, and why that information is so intuitive and useful for drawing conclusions from data.},
  langid = {english},
  keywords = {Statistics},
  annotation = {00000}
}

@book{kruschkeDoingBayesianData2014,
  title = {Doing {{Bayesian Data Analysis}}: {{A Tutorial Introduction}} with {{R}}},
  shorttitle = {Doing {{Bayesian Data Analysis}}},
  author = {Kruschke, John K.},
  date = {2014},
  edition = {2nd Edition},
  publisher = {{Academic Press}},
  location = {{Burlington, MA}},
  abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis, A Tutorial Introduction with R and BUGS, provides an accessible approach to Bayesian Data Analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. The text delivers comprehensive coverage of all scenarios addressed by non-Bayesian textbooks- t-tests, analysis of variance (ANOVA) and comparisons in ANOVA, multiple regression, and chi-square (contingency table analysis). This book is intended for first year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Prerequisite is knowledge of algebra and basic calculus. Free software now includes programs in JAGS, which runs on Macintosh, Linux, and Windows. Author website: http://www.indiana.edu/\textasciitilde kruschke/DoingBayesianDataAnalysis/Provides complete examples with R programming language and BUGS software (both Freeware)  Addresses topics such as experiment planning, power analysis and sample size planning Includes numerous exercises with explicit purposes and guidelines for accomplishment.},
  isbn = {978-0-12-381486-9},
  langid = {english},
  pagetotal = {673},
  keywords = {\_tablet,Mathematics / Applied,Mathematics / General,Mathematics / Probability \& Statistics / Bayesian Analysis,Mathematics / Probability \& Statistics / General,r,stan,Statistics},
  annotation = {00000}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {{{CRC}} Texts in Statistical Science},
  edition = {2},
  publisher = {{Taylor and Francis, CRC Press}},
  location = {{Boca Raton}},
  abstract = {"Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
  isbn = {978-0-367-13991-9},
  langid = {english},
  keywords = {\_tablet}
}

@article{ravenzwaaijSimpleIntroductionMarkov2016,
  title = {A Simple Introduction to {{Markov Chain Monte}}\textendash{{Carlo}} Sampling},
  author = {family=Ravenzwaaij, given=Don, prefix=van, useprefix=false and Cassey, Pete and Brown, Scott D.},
  date = {2016-03-11},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  pages = {1--12},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1015-8},
  url = {http://link.springer.com/article/10.3758/s13423-016-1015-8},
  urldate = {2016-03-23},
  abstract = {Markov Chain Monte\textendash Carlo (MCMC) is an increasingly popular method for obtaining information about distributions, especially for estimating posterior distributions in Bayesian inference. This article provides a very basic introduction to MCMC sampling. It describes what MCMC is, and what it can be used for, with simple illustrative examples. Highlighted are some of the benefits and limitations of MCMC sampling, as well as different approaches to circumventing the limitations most likely to trouble cognitive scientists.},
  langid = {english},
  keywords = {Bayesian inference,Cognitive Psychology,Markov Chain Monte\textendash Carlo,MCMC,Statistics,Tutorial},
  annotation = {00000}
}

@software{rcoreteamLanguageEnvironmentStatistical2023,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}. {{Version}} 4.2.2},
  author = {{R Core Team}},
  date = {2023},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}},
  version = {4.3.0},
  keywords = {\#nosource}
}

@article{scholerInflatingDeflatingSelf2014,
  title = {Inflating and Deflating the Self: {{Sustaining}} Motivational Concerns through Self-Evaluation},
  shorttitle = {Inflating and Deflating the Self},
  author = {Scholer, Abigail A. and Ozaki, Yuka and Higgins, E. Tory},
  date = {2014-03-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {51},
  pages = {60--73},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2013.11.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0022103113001947},
  urldate = {2023-03-17},
  abstract = {The ways in which individuals think and feel about themselves play a significant role in guiding behavior across many domains in life. The current studies investigate how individuals may shift the positivity of self-evaluations in order to sustain their chronic or momentary motivational concerns. Specifically, we propose that more positive self-evaluations support eagerness that sustains promotion-focused concerns with advancement, whereas less positive self-evaluations support vigilance that sustains prevention-focused concerns with safety. The current studies provide evidence that self-evaluation inflation is associated with promotion concerns whereas self-evaluation deflation is associated with prevention concerns, whether regulatory focus is situationally manipulated (Studies 1, 2b, and 3) or measured as a chronic individual difference (Study 2a). Following regulatory focus primes, individuals in a promotion focus showed relatively greater accessibility of positive versus negative self-knowledge compared to individuals in a prevention focus (Study 1). In an ongoing performance situation, participants in a promotion focus reported higher self-esteem than participants in a prevention focus (Studies 2a and 2b). Finally, individuals in a promotion focus persisted longer on an anagram task when given an opportunity to focus on their strengths versus weaknesses, which was not the case for individuals in a prevention focus (Study 3). Across studies, the predicted interactions were consistently obtained, although sometimes the effects were stronger for promotion or prevention motivation. We discuss implications for existing models of the motives underlying self-evaluation.},
  langid = {english},
  keywords = {Motivation,Prevention focus,Promotion focus,Regulatory fit,Regulatory focus,Self-evaluation,Self-regulation}
}
